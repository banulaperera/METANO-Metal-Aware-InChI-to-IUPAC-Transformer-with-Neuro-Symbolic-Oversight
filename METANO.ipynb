{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banulaperera/METANO-Metal-Aware-InChI-to-IUPAC-Transformer-with-Neuro-Symbolic-Oversight/blob/model_dev/METANO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project_overview"
      },
      "source": [
        "# METANO: Metal Aware InChI to IUPAC Transformer with Neuro Symbolic Oversight\n",
        "\n",
        "## Project Overview\n",
        "METANO is an AI-driven software platform designed to automatically translate International Chemical Identifier (InChI) strings, including challenging Reconnect InChI variants, into systematic IUPAC names. This implementation leverages:\n",
        "\n",
        "- **Pre-trained T5 Transformer Model** for sequence-to-sequence translation\n",
        "- **Neurosymbolic Validation** combining neural predictions with chemical rules\n",
        "- **Comprehensive Accuracy Evaluation** with multiple metrics\n",
        "\n",
        "### Key Features\n",
        "- Handles both Standard InChI and Reconnected InChI formats  \n",
        "- Optimized for organometallic and coordination compounds  \n",
        "- Real-time chemical validation and error correction  \n",
        "- Production-ready accuracy metrics and evaluation  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "##  Setup and Installation\n",
        "Install required dependencies and configure the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l1PIm2qKpyh",
        "outputId": "c5676ac4-31cf-4d23-cc08-ee26c8f53b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting RDKit\n",
            "  Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from RDKit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from RDKit) (11.3.0)\n",
            "Downloading rdkit-2025.3.6-cp312-cp312-manylinux_2_28_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: RDKit\n",
            "Successfully installed RDKit-2025.3.6\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install RDKit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_dependencies",
        "outputId": "53b941ca-c200-4f76-f61e-593eb099c96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Import core libraries\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "\n",
        "# Configure logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "for handler in logger.handlers[:]:\n",
        "    logger.removeHandler(handler)\n",
        "logger.propagate = False\n",
        "file_handler = logging.FileHandler('metano_training.log')\n",
        "file_handler.setLevel(logging.INFO)\n",
        "stream_handler = logging.StreamHandler()\n",
        "stream_handler.setLevel(logging.WARNING)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "file_handler.setFormatter(formatter)\n",
        "stream_handler.setFormatter(formatter)\n",
        "logger.addHandler(file_handler)\n",
        "logger.addHandler(stream_handler)\n",
        "\n",
        "# Google drive intergration imports\n",
        "try:\n",
        "  from google.colab import drive, files, auth\n",
        "  from googleapiclient.discovery import build\n",
        "  from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\n",
        "  from io import BytesIO\n",
        "  DRIVE_AVAILABLE = True\n",
        "except:\n",
        "  DRIVE_AVAILABLE = False\n",
        "\n",
        "# Transformers and ML libraries\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "try:\n",
        "    import nltk\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "except ImportError:\n",
        "    logger.warning(\" NLTK not available - BLEU score calculation will be limited\")\n",
        "\n",
        "# Chemical libraries\n",
        "try:\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import Descriptors\n",
        "    logger.info(\" RDKit loaded successfully\")\n",
        "except ImportError:\n",
        "    logger.warning(\" RDKit not available - chemical validation will be limited\")\n",
        "    Chem = None\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\" Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_section"
      },
      "source": [
        "##  Configuration and Hyperparameters\n",
        "Optimized configuration for production-level performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "configuration",
        "outputId": "e2c6891e-344d-4293-c882-4dcd0959d7a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration loaded:\n",
            "   Model: t5-small\n",
            "   Learning rate: 0.0003\n",
            "   Batch size: 4\n",
            "   Max epochs: 20\n",
            "   Device: cpu\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Optimized configuration for METANO model\"\"\"\n",
        "\n",
        "    # Model parameters\n",
        "    model_name: str = \"t5-small\"  # Pre-trained T5 model\n",
        "    max_input_length: int = 512\n",
        "    max_output_length: int = 256\n",
        "\n",
        "    # Training hyperparameters (optimized)\n",
        "    learning_rate: float = 3e-4\n",
        "    weight_decay: float = 0.01\n",
        "    warmup_ratio: float = 0.1\n",
        "    num_epochs: int = 20\n",
        "    batch_size: int = 4  # Reduced batch size to save memory\n",
        "    gradient_accumulation_steps: int = 8 # Increased accumulation steps to compensate\n",
        "\n",
        "    # Validation parameters\n",
        "    eval_steps: int = 500\n",
        "    save_steps: int = 1000\n",
        "    early_stopping_patience: int = 3\n",
        "    eval_strategy: str = \"epoch\"\n",
        "\n",
        "    # Generation parameters\n",
        "    num_beams: int = 4\n",
        "    do_sample: bool = False\n",
        "    temperature: float = 1.0\n",
        "    top_k: int = 50\n",
        "\n",
        "    # Neurosymbolic parameters\n",
        "    enable_chemical_validation: bool = True\n",
        "    enable_grammar_checking: bool = True\n",
        "    enable_metal_coordination_validation: bool = True\n",
        "    confidence_threshold: float = 0.5\n",
        "\n",
        "    # Metal-specific parameters\n",
        "    metal_elements: List[str] = field(default_factory=lambda: [\n",
        "        'Li', 'Na', 'K', 'Rb', 'Cs', 'Be', 'Mg', 'Ca', 'Sr', 'Ba', 'Ra',\n",
        "        'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
        "        'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd',\n",
        "        'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
        "        'Al', 'Ga', 'In', 'Tl', 'Sn', 'Pb', 'Bi'\n",
        "    ])\n",
        "\n",
        "    # Data parameters\n",
        "    train_split: float = 0.7\n",
        "    val_split: float = 0.2\n",
        "    test_split: float = 0.1\n",
        "\n",
        "    # Directory paths\n",
        "    output_dir: str = \"./metano_model\"\n",
        "\n",
        "    # Google Drive checkpoint parameters\n",
        "    use_google_drive: bool = DRIVE_AVAILABLE\n",
        "    gdrive_checkpoint_folder: str = \"METANO_Checkpoints\"\n",
        "    checkpoint_frequency: int = 1  # Save every N epochs\n",
        "    max_checkpoints: int = 5  # Keep only N recent checkpoints\n",
        "    auto_resume: bool = True\n",
        "    backup_to_local: bool = True\n",
        "\n",
        "    # Experiment tracking\n",
        "    experiment_name: str = \"metano_inchi2iupac\"\n",
        "    run_name: str = field(default_factory=lambda: f\"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Create necessary directories\"\"\"\n",
        "        for directory in [self.output_dir, self.cache_dir, self.logs_dir]:\n",
        "            Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Initialize configuration\n",
        "config = ModelConfig()\n",
        "print(\" Configuration loaded:\")\n",
        "print(f\"   Model: {config.model_name}\")\n",
        "print(f\"   Learning rate: {config.learning_rate}\")\n",
        "print(f\"   Batch size: {config.batch_size}\")\n",
        "print(f\"   Max epochs: {config.num_epochs}\")\n",
        "print(f\"   Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRWe9yVNd22a"
      },
      "source": [
        "## Creating Checkpoints\n",
        "Checkpoint management with local and cloud synchronization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy5lN2aeeOSv"
      },
      "outputs": [],
      "source": [
        "class GoogleDriveManager:\n",
        "    \"\"\"Google Drive integration for model checkpoints\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        self.config = config\n",
        "        self.service = None\n",
        "        self.folder_id = None\n",
        "        self.authenticated = False\n",
        "\n",
        "        if config.use_google_drive and DRIVE_AVAILABLE:\n",
        "            self.authenticate()\n",
        "            if self.authenticated:\n",
        "                self.setup_checkpoint_folder()\n",
        "\n",
        "    def authenticate(self):\n",
        "        \"\"\"Authenticate with Google Drive API\"\"\"\n",
        "        try:\n",
        "            if DRIVE_AVAILABLE:\n",
        "                auth.authenticate_user()\n",
        "                self.service = build('drive', 'v3')\n",
        "                self.authenticated = True\n",
        "                logger.info(\" Google Drive authentication successful\")\n",
        "            else:\n",
        "                logger.warning(\" Google Colab not available - skipping Drive authentication\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Google Drive authentication failed: {e}\")\n",
        "            self.config.use_google_drive = False\n",
        "\n",
        "    def setup_checkpoint_folder(self):\n",
        "        \"\"\"Create or locate the checkpoint folder in Google Drive\"\"\"\n",
        "        if not self.authenticated:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Search for existing folder\n",
        "            query = f\"name='{self.config.gdrive_checkpoint_folder}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "            results = self.service.files().list(\n",
        "                q=query,\n",
        "                fields=\"files(id, name, createdTime)\"\n",
        "            ).execute()\n",
        "\n",
        "            folders = results.get('files', [])\n",
        "\n",
        "            if folders:\n",
        "                self.folder_id = folders[0]['id']\n",
        "                logger.info(f\" Found existing checkpoint folder: {self.config.gdrive_checkpoint_folder}\")\n",
        "            else:\n",
        "                # Create new folder\n",
        "                folder_metadata = {\n",
        "                    'name': self.config.gdrive_checkpoint_folder,\n",
        "                    'mimeType': 'application/vnd.google-apps.folder'\n",
        "                }\n",
        "                folder = self.service.files().create(\n",
        "                    body=folder_metadata,\n",
        "                    fields='id'\n",
        "                ).execute()\n",
        "                self.folder_id = folder['id']\n",
        "                logger.info(f\" Created new checkpoint folder: {self.config.gdrive_checkpoint_folder}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Failed to setup checkpoint folder: {e}\")\n",
        "            self.config.use_google_drive = False\n",
        "\n",
        "    def save_checkpoint(self, checkpoint_data: Dict, epoch: int, loss: float, metrics: Dict = None):\n",
        "        \"\"\"Save checkpoint to Google Drive with comprehensive metadata\"\"\"\n",
        "        if not self.authenticated or not self.folder_id:\n",
        "            logger.warning(\" Google Drive not available - skipping cloud backup\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Create detailed checkpoint filename\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            metrics_str = \"\"\n",
        "            if metrics and 'val_loss' in metrics:\n",
        "                metrics_str = f\"_val{metrics['val_loss']:.4f}\"\n",
        "\n",
        "            filename = f\"metano_checkpoint_e{epoch:03d}_loss{loss:.4f}{metrics_str}_{timestamp}.pt\"\n",
        "\n",
        "            # Save checkpoint to temporary file\n",
        "            temp_path = os.path.join(tempfile.gettempdir(), filename)\n",
        "\n",
        "            # Add metadata to checkpoint\n",
        "            enhanced_checkpoint = {\n",
        "                **checkpoint_data,\n",
        "                'save_timestamp': timestamp,\n",
        "                'metrics': metrics or {},\n",
        "                'config_snapshot': self.config.__dict__.copy(),\n",
        "                'device_info': str(device),\n",
        "                'torch_version': torch.__version__\n",
        "            }\n",
        "\n",
        "            torch.save(enhanced_checkpoint, temp_path)\n",
        "\n",
        "            # Upload to Google Drive\n",
        "            file_metadata = {\n",
        "                'name': filename,\n",
        "                'parents': [self.folder_id],\n",
        "                'description': f\"METANO checkpoint - Epoch {epoch}, Loss {loss:.4f}\"\n",
        "            }\n",
        "\n",
        "            media = MediaFileUpload(temp_path, resumable=True)\n",
        "            upload_request = self.service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id,name,size'\n",
        "            )\n",
        "\n",
        "            # Execute upload with progress tracking\n",
        "            response = None\n",
        "            while response is None:\n",
        "                status, response = upload_request.next_chunk()\n",
        "                if status:\n",
        "                    progress = int(status.progress() * 100)\n",
        "                    if progress % 25 == 0:  # Log every 25% progress\n",
        "                        logger.info(f\" Upload progress: {progress}%\")\n",
        "\n",
        "            # Clean up local temp file\n",
        "            os.remove(temp_path)\n",
        "\n",
        "            logger.info(f\" Checkpoint uploaded to Google Drive: {filename}\")\n",
        "            logger.info(f\" File size: {int(response.get('size', 0)) / (1024*1024):.1f} MB\")\n",
        "\n",
        "            # Clean up old checkpoints\n",
        "            self.cleanup_old_checkpoints()\n",
        "\n",
        "            return response['id']\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Failed to save checkpoint to Google Drive: {e}\")\n",
        "            return None\n",
        "\n",
        "    def list_checkpoints(self) -> List[Dict]:\n",
        "        \"\"\"List all checkpoints in Google Drive folder with detailed metadata\"\"\"\n",
        "        if not self.authenticated or not self.folder_id:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            query = f\"'{self.folder_id}' in parents and name contains 'metano_checkpoint' and trashed=false\"\n",
        "            results = self.service.files().list(\n",
        "                q=query,\n",
        "                fields=\"files(id, name, createdTime, modifiedTime, size, description)\",\n",
        "                orderBy=\"createdTime desc\",\n",
        "                pageSize=50\n",
        "            ).execute()\n",
        "\n",
        "            checkpoints = results.get('files', [])\n",
        "\n",
        "            # Parse metadata from filenames\n",
        "            for checkpoint in checkpoints:\n",
        "                filename = checkpoint['name']\n",
        "                # Extract epoch using regex\n",
        "                epoch_match = re.search(r'_e(\\d+)_', filename)\n",
        "                loss_match = re.search(r'_loss([\\d\\.]+)', filename)\n",
        "                val_loss_match = re.search(r'_val([\\d\\.]+)', filename)\n",
        "\n",
        "                checkpoint['parsed_epoch'] = int(epoch_match.group(1)) if epoch_match else 0\n",
        "                checkpoint['parsed_loss'] = float(loss_match.group(1)) if loss_match else float('inf')\n",
        "                checkpoint['parsed_val_loss'] = float(val_loss_match.group(1)) if val_loss_match else None\n",
        "                checkpoint['size_mb'] = int(checkpoint.get('size', 0)) / (1024*1024) if checkpoint.get('size') else 0\n",
        "\n",
        "            return checkpoints\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Failed to list checkpoints: {e}\")\n",
        "            return []\n",
        "\n",
        "    def load_checkpoint(self, checkpoint_id: str = None) -> Dict:\n",
        "        \"\"\"Load checkpoint from Google Drive with enhanced error handling\"\"\"\n",
        "        if not self.authenticated:\n",
        "            logger.warning(\" Google Drive not authenticated\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # If no specific checkpoint ID, get the latest\n",
        "            if checkpoint_id is None:\n",
        "                checkpoints = self.list_checkpoints()\n",
        "                if not checkpoints:\n",
        "                    logger.info(\" No checkpoints found in Google Drive\")\n",
        "                    return None\n",
        "                checkpoint_id = checkpoints[0]['id']  # Latest checkpoint\n",
        "                logger.info(f\" Loading latest checkpoint: {checkpoints[0]['name']}\")\n",
        "\n",
        "            # Download checkpoint with progress tracking\n",
        "            request = self.service.files().get_media(fileId=checkpoint_id)\n",
        "            file_io = BytesIO()\n",
        "            downloader = MediaIoBaseDownload(file_io, request)\n",
        "\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "                if status:\n",
        "                    progress = int(status.progress() * 100)\n",
        "                    if progress % 25 == 0:\n",
        "                        logger.info(f\" Download progress: {progress}%\")\n",
        "\n",
        "            # Load checkpoint data\n",
        "            file_io.seek(0)\n",
        "            checkpoint_data = torch.load(file_io, map_location=device, weights_only=False)\n",
        "\n",
        "            logger.info(\" Checkpoint loaded successfully from Google Drive\")\n",
        "            logger.info(f\" Checkpoint epoch: {checkpoint_data.get('epoch', 'unknown')}\")\n",
        "            logger.info(f\" Checkpoint loss: {checkpoint_data.get('loss', 'unknown')}\")\n",
        "\n",
        "            return checkpoint_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Failed to load checkpoint from Google Drive: {e}\")\n",
        "            return None\n",
        "\n",
        "    def cleanup_old_checkpoints(self):\n",
        "        \"\"\"Remove old checkpoints beyond max_checkpoints limit\"\"\"\n",
        "        if not self.authenticated:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            checkpoints = self.list_checkpoints()\n",
        "\n",
        "            if len(checkpoints) > self.config.max_checkpoints:\n",
        "                # Sort by creation time and keep only the most recent\n",
        "                checkpoints_to_delete = checkpoints[self.config.max_checkpoints:]\n",
        "\n",
        "                for checkpoint in checkpoints_to_delete:\n",
        "                    self.service.files().delete(fileId=checkpoint['id']).execute()\n",
        "                    logger.info(f\" Deleted old checkpoint: {checkpoint['name']}\")\n",
        "\n",
        "                logger.info(f\" Cleaned up {len(checkpoints_to_delete)} old checkpoints\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Failed to cleanup old checkpoints: {e}\")\n",
        "\n",
        "    def get_checkpoint_summary(self) -> Dict:\n",
        "        \"\"\"Get comprehensive summary of all checkpoints\"\"\"\n",
        "        checkpoints = self.list_checkpoints()\n",
        "\n",
        "        if not checkpoints:\n",
        "            return {'total_checkpoints': 0, 'latest_checkpoint': None}\n",
        "\n",
        "        # Calculate summary statistics\n",
        "        total_size_mb = sum(cp.get('size_mb', 0) for cp in checkpoints)\n",
        "        epochs = [cp['parsed_epoch'] for cp in checkpoints if cp['parsed_epoch'] > 0]\n",
        "        losses = [cp['parsed_loss'] for cp in checkpoints if cp['parsed_loss'] < float('inf')]\n",
        "\n",
        "        latest = checkpoints[0]\n",
        "\n",
        "        return {\n",
        "            'total_checkpoints': len(checkpoints),\n",
        "            'total_size_mb': total_size_mb,\n",
        "            'latest_checkpoint': {\n",
        "                'name': latest['name'],\n",
        "                'epoch': latest['parsed_epoch'],\n",
        "                'loss': latest['parsed_loss'],\n",
        "                'created_time': latest['createdTime'],\n",
        "                'size_mb': latest['size_mb']\n",
        "            },\n",
        "            'epoch_range': (min(epochs), max(epochs)) if epochs else (0, 0),\n",
        "            'loss_range': (min(losses), max(losses)) if losses else (0, 0),\n",
        "            'avg_checkpoint_size_mb': total_size_mb / len(checkpoints) if checkpoints else 0\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmFHHae84vxG"
      },
      "outputs": [],
      "source": [
        "class CheckpointManager:\n",
        "    \"\"\"Advanced checkpoint management with local and cloud synchronization\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        self.config = config\n",
        "        self.gdrive_manager = GoogleDriveManager(config) if config.use_google_drive else None\n",
        "        self.local_checkpoint_dir = Path(config.output_dir) / \"checkpoints\"\n",
        "        self.local_checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Initialize checkpoint metadata\n",
        "        self.checkpoint_history = []\n",
        "        self.load_checkpoint_history()\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch: int, loss: float,\n",
        "                       metrics: Dict = None, is_best: bool = False) -> str:\n",
        "        \"\"\"Save checkpoint with comprehensive metadata tracking\"\"\"\n",
        "\n",
        "        # Prepare checkpoint data\n",
        "        checkpoint_data = {\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'epoch': epoch,\n",
        "            'loss': loss,\n",
        "            'metrics': metrics or {},\n",
        "            'config': self.config.__dict__.copy(),\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'device': str(device),\n",
        "            'is_best': is_best,\n",
        "            'torch_version': torch.__version__,\n",
        "            'model_parameters': sum(p.numel() for p in model.parameters())\n",
        "        }\n",
        "\n",
        "        # Generate checkpoint filename\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"checkpoint_e{epoch:03d}_loss{loss:.4f}_{timestamp}.pt\"\n",
        "\n",
        "        # Save locally\n",
        "        local_path = self.local_checkpoint_dir / filename\n",
        "        torch.save(checkpoint_data, local_path)\n",
        "\n",
        "        # Update checkpoint history\n",
        "        checkpoint_info = {\n",
        "            'epoch': epoch,\n",
        "            'loss': loss,\n",
        "            'metrics': metrics or {},\n",
        "            'filename': filename,\n",
        "            'local_path': str(local_path),\n",
        "            'timestamp': checkpoint_data['timestamp'],\n",
        "            'is_best': is_best,\n",
        "            'file_size_mb': local_path.stat().st_size / (1024*1024)\n",
        "        }\n",
        "\n",
        "        self.checkpoint_history.append(checkpoint_info)\n",
        "        self.save_checkpoint_history()\n",
        "\n",
        "        logger.info(f\" Local checkpoint saved: {filename}\")\n",
        "        logger.info(f\" File size: {checkpoint_info['file_size_mb']:.1f} MB\")\n",
        "\n",
        "        # Save best model separately\n",
        "        if is_best:\n",
        "            best_path = Path(self.config.output_dir) / \"best_model.pt\"\n",
        "            torch.save(checkpoint_data, best_path)\n",
        "            logger.info(\" Best model checkpoint saved\")\n",
        "\n",
        "        # Save to Google Drive if enabled and conditions met\n",
        "        gdrive_id = None\n",
        "        if (self.gdrive_manager and\n",
        "            (epoch % self.config.checkpoint_frequency == 0 or is_best)):\n",
        "            gdrive_id = self.gdrive_manager.save_checkpoint(checkpoint_data, epoch, loss, metrics)\n",
        "            if gdrive_id:\n",
        "                checkpoint_info['gdrive_id'] = gdrive_id\n",
        "\n",
        "        # Cleanup old local checkpoints\n",
        "        self.cleanup_local_checkpoints()\n",
        "\n",
        "        return str(local_path)\n",
        "\n",
        "    def load_checkpoint(self, checkpoint_path: str = None, from_gdrive: bool = False,\n",
        "                       epoch: int = None) -> Dict:\n",
        "        \"\"\"Advanced checkpoint loading with multiple fallback options\"\"\"\n",
        "\n",
        "        # Priority order: specific path -> Google Drive -> latest local\n",
        "        checkpoint_data = None\n",
        "\n",
        "        # Option 1: Load specific checkpoint path\n",
        "        if checkpoint_path and Path(checkpoint_path).exists():\n",
        "            checkpoint_data = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "            logger.info(f\" Checkpoint loaded from specified path: {checkpoint_path}\")\n",
        "            return checkpoint_data\n",
        "\n",
        "        # Option 2: Load from Google Drive\n",
        "        if from_gdrive or (checkpoint_path is None and self.config.auto_resume and self.gdrive_manager):\n",
        "            checkpoint_data = self.gdrive_manager.load_checkpoint()\n",
        "            if checkpoint_data:\n",
        "                return checkpoint_data\n",
        "\n",
        "        # Option 3: Load specific epoch from local\n",
        "        if epoch is not None:\n",
        "            matching_checkpoints = [\n",
        "                cp for cp in self.checkpoint_history\n",
        "                if cp['epoch'] == epoch and Path(cp['local_path']).exists()\n",
        "            ]\n",
        "            if matching_checkpoints:\n",
        "                latest_match = max(matching_checkpoints, key=lambda x: x['timestamp'])\n",
        "                checkpoint_data = torch.load(latest_match['local_path'], map_location=device, weights_only=False)\n",
        "                logger.info(f\" Epoch {epoch} checkpoint loaded: {latest_match['filename']}\")\n",
        "                return checkpoint_data\n",
        "\n",
        "        # Option 4: Load latest local checkpoint\n",
        "        if self.checkpoint_history:\n",
        "            # Sort by timestamp and get the latest\n",
        "            sorted_checkpoints = sorted(\n",
        "                self.checkpoint_history,\n",
        "                key=lambda x: x['timestamp'],\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            for checkpoint_info in sorted_checkpoints:\n",
        "                local_path = Path(checkpoint_info['local_path'])\n",
        "                if local_path.exists():\n",
        "                    checkpoint_data = torch.load(local_path, map_location=device, weights_only=False)\n",
        "                    logger.info(f\" Latest local checkpoint loaded: {checkpoint_info['filename']}\")\n",
        "                    return checkpoint_data\n",
        "\n",
        "        logger.info(\" No checkpoints found\")\n",
        "        return None\n",
        "\n",
        "    def load_checkpoint_history(self):\n",
        "        \"\"\"Load checkpoint history from metadata file\"\"\"\n",
        "        history_file = self.local_checkpoint_dir / \"checkpoint_history.json\"\n",
        "        if history_file.exists():\n",
        "            try:\n",
        "                with open(history_file, 'r') as f:\n",
        "                    self.checkpoint_history = json.load(f)\n",
        "                logger.info(f\" Loaded checkpoint history: {len(self.checkpoint_history)} entries\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\" Failed to load checkpoint history: {e}\")\n",
        "                self.checkpoint_history = []\n",
        "\n",
        "    def save_checkpoint_history(self):\n",
        "        \"\"\"Save checkpoint history to metadata file\"\"\"\n",
        "        history_file = self.local_checkpoint_dir / \"checkpoint_history.json\"\n",
        "        try:\n",
        "            with open(history_file, 'w') as f:\n",
        "                json.dump(self.checkpoint_history, f, indent=2)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\" Failed to save checkpoint history: {e}\")\n",
        "\n",
        "    def cleanup_local_checkpoints(self):\n",
        "        \"\"\"Clean up old local checkpoints based on retention policy\"\"\"\n",
        "        if len(self.checkpoint_history) <= self.config.max_checkpoints:\n",
        "            return\n",
        "\n",
        "        # Sort by timestamp and keep only recent ones (excluding best models)\n",
        "        non_best_checkpoints = [cp for cp in self.checkpoint_history if not cp['is_best']]\n",
        "\n",
        "        if len(non_best_checkpoints) > self.config.max_checkpoints:\n",
        "            sorted_checkpoints = sorted(non_best_checkpoints, key=lambda x: x['timestamp'])\n",
        "            checkpoints_to_remove = sorted_checkpoints[:-self.config.max_checkpoints]\n",
        "\n",
        "            for checkpoint_info in checkpoints_to_remove:\n",
        "                local_path = Path(checkpoint_info['local_path'])\n",
        "                if local_path.exists():\n",
        "                    local_path.unlink()\n",
        "                    logger.info(f\" Removed old local checkpoint: {checkpoint_info['filename']}\")\n",
        "\n",
        "                # Remove from history\n",
        "                self.checkpoint_history.remove(checkpoint_info)\n",
        "\n",
        "            self.save_checkpoint_history()\n",
        "\n",
        "    def get_checkpoint_summary(self) -> Dict:\n",
        "        \"\"\"Get comprehensive summary of checkpoint status\"\"\"\n",
        "        local_summary = {\n",
        "            'total_local_checkpoints': len(self.checkpoint_history),\n",
        "            'best_checkpoints': len([cp for cp in self.checkpoint_history if cp['is_best']]),\n",
        "            'total_size_mb': sum(cp.get('file_size_mb', 0) for cp in self.checkpoint_history),\n",
        "            'epoch_range': None,\n",
        "            'latest_checkpoint': None\n",
        "        }\n",
        "\n",
        "        if self.checkpoint_history:\n",
        "            epochs = [cp['epoch'] for cp in self.checkpoint_history]\n",
        "            local_summary['epoch_range'] = (min(epochs), max(epochs))\n",
        "            local_summary['latest_checkpoint'] = max(\n",
        "                self.checkpoint_history, key=lambda x: x['timestamp']\n",
        "            )\n",
        "\n",
        "        # Get Google Drive summary if available\n",
        "        gdrive_summary = {}\n",
        "        if self.gdrive_manager:\n",
        "            gdrive_summary = self.gdrive_manager.get_checkpoint_summary()\n",
        "\n",
        "        return {\n",
        "            'local': local_summary,\n",
        "            'google_drive': gdrive_summary,\n",
        "            'sync_enabled': self.config.use_google_drive and self.gdrive_manager is not None\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_section"
      },
      "source": [
        "##  Data Loading and Preprocessing\n",
        "Load and preprocess the InChI-IUPAC dataset with robust validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "4614cdd51681483bbc4ce61fe0155081",
            "5be1a37f79c148a0943381a4a5a3c198",
            "8451467cfee240f4bbad1b125bdc5d99",
            "f69d6dbc5bcb4bea921655e67325ee39",
            "6255ba44d77d4504af7dbd7d5a631a80",
            "834450b620a340cb93782911d62a72c1",
            "381d9c4e795a4e2088f56540a1495843",
            "e2da89609ace447bbaf6f0a63a113e20",
            "a1fa8b2a2bec400ea8505b12ced9b783",
            "82b81f4f82464e909c8c8d733c1d9fde",
            "68fde888e32d453f8c7e88a1b2709d8a"
          ]
        },
        "id": "data_loader",
        "outputId": "8f9193e4-b04c-4394-9d0a-fd8e754124a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4614cdd51681483bbc4ce61fe0155081",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing lines:   0%|          | 0/67781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Dataset Analysis:\n",
            "   Total pairs: 67781\n",
            "   InChI formats: {'standard': 67781, 'reconnected': 0, 'unknown': 0}\n",
            "   Contains metals: 67781\n",
            "   Avg InChI length: 45.1\n",
            "   Avg IUPAC length: 33.9\n",
            "   Top metals: {'In': 67781, 'Na': 4667, 'K': 3947, 'Al': 3542, 'Fe': 3164}\n",
            "\n",
            " Sample pairs:\n",
            "   1. InChI: InChI=1S/H3N/h1H3\n",
            "      IUPAC: ammonia\n",
            "   2. InChI: InChI=1S/H3N/h1H3/p+1\n",
            "      IUPAC: azanium\n",
            "   3. InChI: InChI=1S/AsH3O4/c2-1(3,4)5/h(H3,2,3,4,5)/p-2\n",
            "      IUPAC: hydrogen arsorate\n"
          ]
        }
      ],
      "source": [
        "class MetanoDatasetLoader:\n",
        "    \"\"\"Enhanced dataset loader with chemical validation\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def create_sample_dataset(self) -> List[Tuple[str, str]]:\n",
        "        \"\"\"Create a sample dataset for demonstration\"\"\"\n",
        "        sample_data = [\n",
        "            # Organic compounds\n",
        "            (\"InChI=1S/CH4/h1H4\", \"methane\"),\n",
        "            (\"InChI=1S/C2H6/c1-2/h1-2H3\", \"ethane\"),\n",
        "            (\"InChI=1S/C2H6O/c1-2-3/h3H,2H2,1H3\", \"ethanol\"),\n",
        "            (\"InChI=1S/C6H6/c1-2-4-6-5-3-1/h1-6H\", \"benzene\"),\n",
        "            (\"InChI=1S/C7H8/c1-7-5-3-2-4-6-7/h2-6H,1H3\", \"toluene\"),\n",
        "            (\"InChI=1S/C8H10/c1-3-7-5-4-6-8(2)9-7/h4-6H,3H2,1-2H3\", \"ethylbenzene\"),\n",
        "\n",
        "            # Organometallic compounds (reconnected InChI)\n",
        "            (\"InChI=1/2C5H5.Fe/c2*1-2-4-5-3-1;/h2*1-5H;/rC10H10Fe/c1-2-4-8-6(1)11-7-3-1-5-9(7)10(11)12-8/h1-10H\",\n",
        "             \"bis(η⁵-cyclopentadienyl)iron\"),\n",
        "            (\"InChI=1/4CO.Co/c4*1-2;/rC4CoO4/c6-1-5(2-7,3-8)4-9/o1-2,2-3,3-4,4-1\",\n",
        "             \"tetracarbonylcobalt(0)\"),\n",
        "            (\"InChI=1/6CO.Cr/c6*1-2;/rC6CrO6/c7-1-8(2-9,3-10,4-11,5-12)6-13\",\n",
        "             \"hexacarbonylchromium(0)\"),\n",
        "            (\"InChI=1/4C18H15P.Ni/c4*1-4-10-16(11-5-1)19(17-12-6-2-7-13-17)18-14-8-3-9-15-18;/h4*1-15H;\",\n",
        "             \"tetrakis(triphenylphosphine)nickel(0)\"),\n",
        "\n",
        "            # Complex organics\n",
        "            (\"InChI=1S/C9H8O/c10-8-7-9-5-3-1-2-4-6-9/h1-8H\", \"benzaldehyde\"),\n",
        "            (\"InChI=1S/C7H6O2/c8-6-7-4-2-1-3-5-7-9/h1-5H,(H,8,9)\", \"benzoic acid\"),\n",
        "            (\"InChI=1S/C6H12O6/c7-1-2-3(8)4(9)5(10)6(11)12-2/h2-11H,1H2/t2-,3-,4+,5-,6+/m1/s1\",\n",
        "             \"α-D-glucopyranose\"),\n",
        "\n",
        "            # Coordination compounds\n",
        "            (\"InChI=1/6H3N.Co.3ClH/h6*1H3;;3*1H/q;;3*-1;+3\", \"hexaamminecobalt(III) chloride\"),\n",
        "            (\"InChI=1/2C10H8N2.Fe/c2*1-3-9-5-6-10-4-2-8-12-11-9;/h2*1-8H;\",\n",
        "             \"bis(2,2'-bipyridine)iron(II)\"),\n",
        "\n",
        "            # More organometallics\n",
        "            (\"InChI=1/C8H8.Fe/c1-2-4-6-8-7-5-3-1;/h1-8H;\", \"(η⁸-cyclooctatetraene)iron\"),\n",
        "        ]\n",
        "\n",
        "        # Expand dataset with variations\n",
        "        expanded_data = sample_data * 50  # Duplicate for training\n",
        "        random.shuffle(expanded_data)\n",
        "\n",
        "        return expanded_data\n",
        "\n",
        "    def load_from_file(self, file_path: str, limit: Optional[int] = None) -> List[Tuple[str, str]]:\n",
        "        \"\"\"Load dataset from tab-separated file\"\"\"\n",
        "        data = []\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            logger.warning(f\" File not found: {file_path}\")\n",
        "            logger.info(\" Creating sample dataset for demonstration...\")\n",
        "            return self.create_sample_dataset()\n",
        "\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            logger.info(f\" Loading dataset from {file_path}\")\n",
        "            valid_count = 0\n",
        "            invalid_count = 0\n",
        "\n",
        "            for line_num, line in enumerate(tqdm(lines, desc=\"Processing lines\")):\n",
        "                if limit is not None and len(data) >= limit:\n",
        "                    logger.info(f\" Reached specified limit of {limit} lines.\")\n",
        "                    break\n",
        "\n",
        "                line = line.strip()\n",
        "                if not line or line.startswith('#'):\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    parts = line.split('\\t')\n",
        "                    if len(parts) >= 2:\n",
        "                        inchi = parts[0].strip()\n",
        "                        iupac = parts[1].strip()\n",
        "\n",
        "                        if self._validate_pair(inchi, iupac):\n",
        "                            data.append((inchi, iupac))\n",
        "                            valid_count += 1\n",
        "                        else:\n",
        "                            invalid_count += 1\n",
        "                except Exception as e:\n",
        "                    invalid_count += 1\n",
        "                    continue\n",
        "\n",
        "            logger.info(f\" Loaded {valid_count} valid pairs\")\n",
        "            logger.info(f\" Filtered {invalid_count} invalid pairs\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Error loading file: {e}\")\n",
        "            logger.info(\" Using sample dataset instead...\")\n",
        "            return self.create_sample_dataset()\n",
        "\n",
        "        return data if data else self.create_sample_dataset()\n",
        "\n",
        "    def _validate_pair(self, inchi: str, iupac: str) -> bool:\n",
        "        \"\"\"Validate InChI-IUPAC pair\"\"\"\n",
        "        # Basic format checks\n",
        "        if not inchi or not iupac:\n",
        "            return False\n",
        "\n",
        "        if not inchi.startswith('InChI='):\n",
        "            return False\n",
        "\n",
        "        if len(inchi) < 10 or len(iupac) < 2:\n",
        "            return False\n",
        "\n",
        "        # Check for invalid IUPAC names\n",
        "        invalid_names = ['unknown', 'error', 'invalid', 'n/a', 'none']\n",
        "        if iupac.lower().strip() in invalid_names:\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def analyze_dataset(self, data: List[Tuple[str, str]]) -> Dict:\n",
        "        \"\"\"Analyze dataset composition\"\"\"\n",
        "        analysis = {\n",
        "            'total_pairs': len(data),\n",
        "            'inchi_formats': {'standard': 0, 'reconnected': 0, 'unknown': 0},\n",
        "            'has_metals': 0,\n",
        "            'avg_inchi_length': 0,\n",
        "            'avg_iupac_length': 0,\n",
        "            'metal_distribution': {},\n",
        "            'sample_pairs': []\n",
        "        }\n",
        "\n",
        "        inchi_lengths = []\n",
        "        iupac_lengths = []\n",
        "\n",
        "        for i, (inchi, iupac) in enumerate(data):\n",
        "            inchi_lengths.append(len(inchi))\n",
        "            iupac_lengths.append(len(iupac))\n",
        "\n",
        "            # Format analysis\n",
        "            if 'InChI=1S/' in inchi:\n",
        "                analysis['inchi_formats']['standard'] += 1\n",
        "            elif '/r' in inchi:\n",
        "                analysis['inchi_formats']['reconnected'] += 1\n",
        "            else:\n",
        "                analysis['inchi_formats']['unknown'] += 1\n",
        "\n",
        "            # Metal analysis\n",
        "            metals_found = [m for m in self.config.metal_elements if m in inchi]\n",
        "            if metals_found:\n",
        "                analysis['has_metals'] += 1\n",
        "                for metal in metals_found:\n",
        "                    analysis['metal_distribution'][metal] = analysis['metal_distribution'].get(metal, 0) + 1\n",
        "\n",
        "            # Sample pairs\n",
        "            if i < 3:\n",
        "                analysis['sample_pairs'].append({\n",
        "                    'inchi': inchi[:60] + '...' if len(inchi) > 60 else inchi,\n",
        "                    'iupac': iupac\n",
        "                })\n",
        "\n",
        "        analysis['avg_inchi_length'] = np.mean(inchi_lengths) if inchi_lengths else 0\n",
        "        analysis['avg_iupac_length'] = np.mean(iupac_lengths) if iupac_lengths else 0\n",
        "\n",
        "        return analysis\n",
        "\n",
        "# Load and analyze dataset\n",
        "logger.info(\" Loading InChI-IUPAC dataset...\")\n",
        "loader = MetanoDatasetLoader(config)\n",
        "\n",
        "# Try to load from file or create sample data\n",
        "dataset_path = \"/content/InorganicInchiNames.txt\"\n",
        "data = loader.load_from_file(dataset_path, limit=1000) # Load a small subset\n",
        "\n",
        "# Analyze dataset\n",
        "analysis = loader.analyze_dataset(data)\n",
        "print(f\"\\n Dataset Analysis:\")\n",
        "print(f\"   Total pairs: {analysis['total_pairs']}\")\n",
        "print(f\"   InChI formats: {analysis['inchi_formats']}\")\n",
        "print(f\"   Contains metals: {analysis['has_metals']}\")\n",
        "print(f\"   Avg InChI length: {analysis['avg_inchi_length']:.1f}\")\n",
        "print(f\"   Avg IUPAC length: {analysis['avg_iupac_length']:.1f}\")\n",
        "\n",
        "if analysis['metal_distribution']:\n",
        "    top_metals = dict(sorted(analysis['metal_distribution'].items(), key=lambda x: x[1], reverse=True)[:5])\n",
        "    print(f\"   Top metals: {top_metals}\")\n",
        "\n",
        "print(f\"\\n Sample pairs:\")\n",
        "for i, sample in enumerate(analysis['sample_pairs']):\n",
        "    print(f\"   {i+1}. InChI: {sample['inchi']}\")\n",
        "    print(f\"      IUPAC: {sample['iupac']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neurosymbolic_section"
      },
      "source": [
        "##  Neurosymbolic Validation System\n",
        "Implement chemical rule-based validation and correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neurosymbolic_validator",
        "outputId": "b8ccb5b6-456e-4173-cd39-ec069870660a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Testing Enhanced Validation:\n",
            "\n",
            "Test Case 1:\n",
            "   Input: bis(η⁵-cyclopentadienyl)iron\n",
            "   Valid: True\n",
            "   Confidence: 0.700\n",
            "   Scores: {'grammar': 1.0, 'metal_coordination': 0.7, 'stereochemistry': 0.9, 'structure_consistency': 0.3, 'nomenclature': 1.0, 'attention_quality': 0.8}\n",
            "\n",
            "Test Case 2:\n",
            "   Input: benzene\n",
            "   Valid: True\n",
            "   Confidence: 0.920\n",
            "   Scores: {'grammar': 1.0, 'metal_coordination': 0.3, 'stereochemistry': 1.0, 'structure_consistency': 1.0, 'nomenclature': 1.0, 'attention_quality': 0.8}\n",
            "\n",
            "Test Case 3:\n",
            "   Input: -----\n",
            "   Valid: False\n",
            "   Confidence: 0.665\n",
            "   Scores: {'grammar': 0.1, 'metal_coordination': 0.3, 'stereochemistry': 1.0, 'structure_consistency': 1.0, 'nomenclature': 0.8, 'attention_quality': 0.8}\n",
            "   Errors: ['Grammar score: 0.100']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[09:55:13] ERROR: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "class ChemicalValidator:\n",
        "    \"\"\"Neurosymbolic chemical validation system\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "      self.config = config\n",
        "\n",
        "      # Chemical grammar rules\n",
        "      self.grammar_rules = {\n",
        "          'required_patterns': [\n",
        "              r'^[a-zA-Z]',  # Must start with letter\n",
        "              r'[a-zA-Z0-9]$'  # Must end with alphanumeric\n",
        "          ],\n",
        "          'forbidden_patterns': [\n",
        "              r'--',  # Double dashes\n",
        "              r',,',  # Double commas\n",
        "              r'\\(\\)',  # Empty parentheses\n",
        "              r'\\[\\]',  # Empty brackets\n",
        "              r'  ',  # Double spaces\n",
        "          ],\n",
        "          'valid_chars': set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "                            '()[]{},-+⁰¹²³⁴⁵⁶⁷⁸⁹⁺⁻₀₁₂₃₄₅₆₇₈₉ηκμλΔΛ ')\n",
        "      }\n",
        "\n",
        "      # Stereochemistry validation\n",
        "      self.stereo_patterns = {\n",
        "            'chirality': [r'\\([RS]\\)', r'\\(R\\)', r'\\(S\\)', r'\\(\\d+[RS]\\)', r'\\(\\d+R\\)', r'\\(\\d+S\\)'],\n",
        "            'geometry': [r'\\([EZ]\\)', r'\\(E\\)', r'\\(Z\\)'],\n",
        "            'coordination': [r'fac-', r'mer-', r'cis-', r'trans-', r'Δ', r'Λ'],\n",
        "            'haptic': [r'η[1-8]', r'η⁵', r'η⁶', r'η¹', r'η²', r'η³', r'η⁴', r'η⁷', r'η⁸']\n",
        "        }\n",
        "\n",
        "      # Metal nomenclature patterns\n",
        "      self.metal_nomenclature = {\n",
        "            'Fe': [\n",
        "                r'\\biron\\b', r'\\bferr\\w*', r'\\bferrocene\\b',\n",
        "                r'bis\\([^)]*cyclopentadienyl[^)]*\\)iron',\n",
        "                r'cyclopentadienyl.*iron', r'iron.*cyclopentadienyl'\n",
        "            ],\n",
        "            'Co': [r'\\bcobalt\\b', r'\\bcob\\w*'],\n",
        "            'Ni': [r'\\bnickel\\b', r'\\bnick\\w*'],\n",
        "            'Cu': [r'\\bcopper\\b', r'\\bcupr\\w*', r'\\bcupro\\w*'],\n",
        "            'Zn': [r'\\bzinc\\b'],\n",
        "            'Mn': [r'\\bmanganese\\b', r'\\bmangan\\w*'],\n",
        "            'Cr': [r'\\bchromium\\b', r'\\bchrom\\w*'],\n",
        "            'Ti': [r'\\btitanium\\b', r'\\btitan\\w*'],\n",
        "            'Pt': [r'\\bplatinum\\b', r'\\bplatin\\w*'],\n",
        "            'Pd': [r'\\bpalladium\\b', r'\\bpallad\\w*'],\n",
        "            'Au': [r'\\bgold\\b', r'\\baur\\w*'],\n",
        "            'Ag': [r'\\bsilver\\b', r'\\bargent\\w*'],\n",
        "            'V': [r'\\bvanadium\\b', r'\\bvanad\\w*'],\n",
        "            'W': [r'\\btungsten\\b', r'\\bwolfram\\w*'],\n",
        "            'Mo': [r'\\bmolybdenum\\b', r'\\bmolybden\\w*'],\n",
        "            'Ru': [r'\\bruthenium\\b', r'\\bruthen\\w*'],\n",
        "            'Rh': [r'\\brhodium\\b', r'\\brhod\\w*'],\n",
        "            'Os': [r'\\bosmium\\b', r'\\bosm\\w*'],\n",
        "            'Ir': [r'\\biridium\\b', r'\\birid\\w*']\n",
        "        }\n",
        "\n",
        "      logger.info(\" Chemical Validator initialized\")\n",
        "\n",
        "    def validate_prediction(self, inchi: str, predicted_iupac: str, attention_weights: Optional[np.ndarray] = None) -> Dict:\n",
        "      \"\"\"Comprehensive validation of predicted IUPAC name\"\"\"\n",
        "      validation_result = {\n",
        "          'is_valid': True,\n",
        "          'confidence': 1.0,\n",
        "          'errors': [],\n",
        "          'warnings': [],\n",
        "          'scores': {},\n",
        "          'detailed_analysis': {}\n",
        "      }\n",
        "\n",
        "      # Grammar validation\n",
        "      grammar_score = self._validate_grammar(predicted_iupac)\n",
        "      validation_result['scores']['grammar'] = grammar_score\n",
        "      if grammar_score < 0.5:\n",
        "          validation_result['is_valid'] = False\n",
        "          validation_result['errors'].append(f\"Grammar score: {grammar_score:.3f}\")\n",
        "\n",
        "      # Metal coordination validation\n",
        "      metal_score = self._validate_metal_coordination(inchi, predicted_iupac)\n",
        "      validation_result['scores']['metal_coordination'] = metal_score\n",
        "\n",
        "      # Stereochemistry validation\n",
        "      stereo_score = self._validate_stereochemistry(inchi, predicted_iupac)\n",
        "      validation_result['scores']['stereochemistry'] = stereo_score\n",
        "\n",
        "      # Chemical structure validation (if RDKit available)\n",
        "      structure_score = self._validate_chemical_structure(inchi)\n",
        "      validation_result['scores']['structure_consistency'] = structure_score\n",
        "\n",
        "      # IUPAC nomenclature rules\n",
        "      nomenclature_score = self._validate_iupac_nomenclature(predicted_iupac, inchi)\n",
        "      validation_result['scores']['nomenclature'] = nomenclature_score\n",
        "\n",
        "      # Attention-based validation (if available)\n",
        "      if attention_weights is not None:\n",
        "          attention_score = self._validate_attention_patterns(attention_weights)\n",
        "          validation_result['scores']['attention_quality'] = attention_score\n",
        "      else:\n",
        "          validation_result['scores']['attention_quality'] = 0.8 # Neutral if not available\n",
        "\n",
        "      # Aggregate scores\n",
        "      scores = validation_result['scores']\n",
        "      # Adaptive weighting based on compound type\n",
        "      if self._is_organometallic_compound(inchi, predicted_iupac):\n",
        "          weights = {\n",
        "              'grammar': 0.15,\n",
        "              'metal_coordination': 0.35,  # Higher for organometallics\n",
        "              'stereochemistry': 0.10,\n",
        "              'structure_consistency': 0.25,\n",
        "              'nomenclature': 0.10,\n",
        "              'attention_quality': 0.05\n",
        "          }\n",
        "      else:\n",
        "          weights = {\n",
        "              'grammar': 0.25,\n",
        "              'metal_coordination': 0.10,  # Lower for organic compounds\n",
        "              'stereochemistry': 0.20,\n",
        "              'structure_consistency': 0.25,\n",
        "              'nomenclature': 0.15,\n",
        "              'attention_quality': 0.05\n",
        "          }\n",
        "\n",
        "      weighted_score = sum(scores.get(key, 0) * weight\n",
        "                           for key, weight in weights.items())\n",
        "      validation_result['confidence'] = weighted_score\n",
        "\n",
        "      # Determine validity\n",
        "      if weighted_score < self.config.confidence_threshold:\n",
        "          validation_result['is_valid'] = False\n",
        "          validation_result['errors'].append(f\"Low confidence score: {weighted_score:.3f}\")\n",
        "\n",
        "      # Add detailed analysis\n",
        "      validation_result['detailed_analysis'] = self._generate_detailed_analysis(\n",
        "          inchi, predicted_iupac, validation_result\n",
        "      )\n",
        "\n",
        "      return validation_result\n",
        "\n",
        "    def _validate_grammar(self, iupac: str) -> float:\n",
        "      \"\"\"Validate IUPAC grammar with chemical specific rules\"\"\"\n",
        "      score = 1.0\n",
        "\n",
        "      # Character validation\n",
        "      invalid_chars = set(iupac) - self.grammar_rules['valid_chars']\n",
        "      if invalid_chars:\n",
        "        score *= 0.3\n",
        "\n",
        "      # Pattern validation\n",
        "      for pattern in self.grammar_rules['forbidden_patterns']:\n",
        "          if re.search(pattern, iupac):\n",
        "              score *= 0.4\n",
        "\n",
        "      for pattern in self.grammar_rules['required_patterns']:\n",
        "          if not re.search(pattern, iupac):\n",
        "              score *= 0.5\n",
        "\n",
        "      # Length validation\n",
        "      if len(iupac.strip()) < 2:\n",
        "        score *= 0.1\n",
        "      # If the name is very long, it can be a malformed name\n",
        "      elif len(iupac.strip()) > 200:\n",
        "        score *= 0.8\n",
        "\n",
        "      # Parenthese/bracket balance\n",
        "      if not self._check_bracket_balance(iupac):\n",
        "        score *= 0.4\n",
        "\n",
        "      return max(0.0, min(1.0, score))\n",
        "\n",
        "    def _check_bracket_balance(self, text: str) -> bool:\n",
        "      \"\"\"Check if parentheses and brackets are balanced\"\"\"\n",
        "      stack = []\n",
        "      pairs = {'(':')', '[':']', '{':'}'}\n",
        "\n",
        "      for char in text:\n",
        "          if char in pairs:\n",
        "              stack.append(char)\n",
        "          elif char in pairs.values():\n",
        "              if not stack or pairs[stack.pop()] != char:\n",
        "                  return False\n",
        "\n",
        "      return len(stack) == 0\n",
        "\n",
        "    def _is_organometallic_compound(self, inchi: str, iupac: str) -> bool:\n",
        "      \"\"\"Determine if compound is organometallic\"\"\"\n",
        "      # Check for metals in InChI\n",
        "      has_metals = any(metal in inchi for metal in self.config.metal_elements)\n",
        "\n",
        "      # Check for organometallic indicators in IUPAC\n",
        "      organometallic_indicators = [\n",
        "          'η', 'cyclopentadienyl', 'carbonyl', 'ferrocene', 'metallocene',\n",
        "          'bis(', 'tris(', 'tetrakis(', 'coordination', 'complex'\n",
        "      ]\n",
        "      has_organometallic_terms = any(indicator in iupac.lower() for indicator in organometallic_indicators)\n",
        "\n",
        "      # Check for reconnection layer (coordination compounds)\n",
        "      has_coordination = '/r' in inchi\n",
        "\n",
        "      return has_metals and (has_organometallic_terms or has_coordination)\n",
        "\n",
        "\n",
        "    def _validate_metal_coordination(self, inchi: str, iupac: str) -> float:\n",
        "      \"\"\"Validate metal coordination consistency\"\"\"\n",
        "\n",
        "      score = 1.0\n",
        "\n",
        "      # Extract metal from InChI\n",
        "      inchi_metals = []\n",
        "      metal_elements = self.config.metal_elements\n",
        "\n",
        "      for metal in metal_elements:\n",
        "        if metal in inchi:\n",
        "          inchi_metals.append(metal)\n",
        "\n",
        "      # Check for metal names in IUPAC\n",
        "      iupac_metals = []\n",
        "      iupac_lower = iupac.lower()\n",
        "\n",
        "      for metal, patterns in self.metal_nomenclature.items():\n",
        "        for pattern in patterns:\n",
        "          if re.search(pattern, iupac_lower):\n",
        "            iupac_metals.append(metal)\n",
        "            break # If metal found then move to next\n",
        "\n",
        "      # If no metals in either, perfect score\n",
        "      if not inchi_metals and not iupac_metals:\n",
        "        return 1.0\n",
        "\n",
        "      # If metals only in one source, check if it's a known exception\n",
        "      if not inchi_metals or not iupac_metals:\n",
        "        # Special case: some organomettallic names don;t explicitly metion the metal\n",
        "        if 'ferrocene' in iupac_lower and 'Fe' in inchi_metals:\n",
        "          return 0.9 # Good but not perfect\n",
        "        return 0.3 # mismatch penalty\n",
        "\n",
        "      common_metals = set(inchi_metals) & set(iupac_metals)\n",
        "      total_metals = set(inchi_metals) | set(iupac_metals)\n",
        "\n",
        "      if total_metals:\n",
        "        metal_overlap = len(common_metals) / len(total_metals)\n",
        "        score = metal_overlap\n",
        "      else:\n",
        "        score = 1.0\n",
        "\n",
        "      # Check coordination number consistency\n",
        "      if '/r' in inchi: # Reconnected InChI indicates coordination\n",
        "        coordination_indicators = ['bis', 'tris', 'tetrakis', 'pentakis', 'hexakis',\n",
        "                'η', 'cyclopentadienyl', 'carbonyl', 'complex']\n",
        "        has_coordination_language = any(indicator in iupac_lower\n",
        "                                        for indicator in coordination_indicators)\n",
        "        if has_coordination_language:\n",
        "          score = min(1.0, score + 0.2)\n",
        "        else:\n",
        "          score *= 0.7 # Penalty for missing coordination language\n",
        "\n",
        "      return max(0.0, min(1.0, score))\n",
        "\n",
        "    def _validate_stereochemistry(self, inchi: str, iupac: str) -> float:\n",
        "      \"\"\"Validate stereochemistry consistency\"\"\"\n",
        "      score = 1.0\n",
        "\n",
        "      # Check for stereochemistry in InChI\n",
        "      has_inchi_stereo = bool(re.search(r'/[tms]', inchi))\n",
        "\n",
        "      # Check for stereochemistry in IUPAC\n",
        "      has_iupac_stereo = any(\n",
        "          any(re.search(pattern, iupac, re.IGNORECASE) for pattern in patterns)\n",
        "          for patterns in self.stereo_patterns.values()\n",
        "      )\n",
        "\n",
        "      # Consistency check\n",
        "      if has_inchi_stereo and has_iupac_stereo:\n",
        "          score = 1.0  # Perfect match\n",
        "      elif not has_inchi_stereo and not has_iupac_stereo:\n",
        "          score = 1.0  # Perfect match (no stereochemistry)\n",
        "      elif has_inchi_stereo and not has_iupac_stereo:\n",
        "          score = 0.7  # Missing stereochemistry (moderate penalty)\n",
        "      else:  # not has_inchi_stereo and has_iupac_stereo\n",
        "          score = 0.9  # Extra stereochemistry (minor penalty)\n",
        "\n",
        "      return max(0.0, min(1.0, score))\n",
        "\n",
        "    def _validate_chemical_structure(self, inchi: str) -> float:\n",
        "      \"\"\"Validate chemical structure using RDKit\"\"\"\n",
        "      score = 1.0\n",
        "\n",
        "      try:\n",
        "          if Chem:\n",
        "              mol = Chem.MolFromInchi(inchi)\n",
        "              if mol is None:\n",
        "                  return 0.3  # Invalid InChI structure\n",
        "\n",
        "              # Basic structure validation\n",
        "              num_atoms = mol.GetNumAtoms()\n",
        "              num_bonds = mol.GetNumBonds()\n",
        "\n",
        "              if num_atoms == 0:\n",
        "                  return 0.0\n",
        "\n",
        "              # More sophisticated scoring based on chemical reasonableness\n",
        "              if num_atoms < 50:  # Small to medium molecules\n",
        "                  score = 0.9\n",
        "              elif num_atoms < 100:  # Large molecules\n",
        "                  score = 0.8\n",
        "              else:  # Very large molecules\n",
        "                  score = 0.7\n",
        "\n",
        "              # Check for reasonable atom types\n",
        "              try:\n",
        "                  # This would normally check for chemically reasonable structures\n",
        "                  formula = Chem.rdMolDescriptors.CalcMolFormula(mol)\n",
        "                  if formula:\n",
        "                      score = min(1.0, score + 0.1)\n",
        "              except:\n",
        "                  score *= 0.9\n",
        "\n",
        "          else:\n",
        "              # Fallback validation without RDKit\n",
        "              if 'InChI=' in inchi and len(inchi) > 10:\n",
        "                  score = 0.8  # Reasonable assumption\n",
        "              else:\n",
        "                  score = 0.3  # Suspicious InChI\n",
        "\n",
        "      except Exception:\n",
        "          score = 0.5  # Neutral score for exceptions\n",
        "\n",
        "      return max(0.0, min(1.0, score))\n",
        "\n",
        "    def _validate_iupac_nomenclature(self, iupac: str, inchi: str) -> float:\n",
        "      \"\"\"Validate IUPAC nomenclature\"\"\"\n",
        "      score = 1.0\n",
        "      iupac_lower = iupac.lower()\n",
        "\n",
        "      # Check if it's organometallic compound\n",
        "      is_organometallic = self._is_organometallic_compound(inchi, iupac)\n",
        "\n",
        "      if is_organometallic:\n",
        "          # Specific validation for organometallic compounds\n",
        "          organometallic_terms = [\n",
        "              'bis(', 'tris(', 'tetrakis(', 'η', 'cyclopentadienyl',\n",
        "              'carbonyl', 'ferrocene', 'metallocene', 'complex'\n",
        "          ]\n",
        "          has_organometallic_nomenclature = any(\n",
        "              term in iupac_lower for term in organometallic_terms\n",
        "          )\n",
        "\n",
        "          if has_organometallic_nomenclature:\n",
        "              score = 1.0\n",
        "          else:\n",
        "              # Check for metal names which is also valid\n",
        "              metal_names = ['iron', 'cobalt', 'nickel', 'copper', 'zinc']\n",
        "              has_metal_names = any(name in iupac_lower for name in metal_names)\n",
        "              score = 0.8 if has_metal_names else 0.6\n",
        "\n",
        "      else:\n",
        "          # Validation for organic compounds\n",
        "          valid_endings = ['ane', 'ene', 'yne', 'ol', 'al', 'one', 'oic', 'ate', 'ide']\n",
        "          organic_compounds = ['benzene', 'toluene', 'phenol', 'aniline', 'methane', 'ethane']\n",
        "\n",
        "          has_valid_ending = (\n",
        "              any(iupac_lower.endswith(ending) for ending in valid_endings) or\n",
        "              any(compound in iupac_lower for compound in organic_compounds)\n",
        "          )\n",
        "\n",
        "          if has_valid_ending:\n",
        "              score = 1.0\n",
        "          else:\n",
        "              score = 0.8  # Less harsh penalty\n",
        "\n",
        "      return max(0.0, min(1.0, score))\n",
        "\n",
        "    def _validate_attention_pattern(self, attention_weights: np.ndarray) -> float:\n",
        "      \"\"\"Validate attention patterns for chemical relevance\"\"\"\n",
        "      score = 1.0\n",
        "\n",
        "      if attention_weights is None or len(attention_weights.shape) < 2:\n",
        "        return 0.8\n",
        "\n",
        "      # Basic attention quality metrics\n",
        "      try:\n",
        "          attention_entropy = -np.sum(attention_weights * np.log(attention_weights + 1e-12), axis=-1)\n",
        "          avg_entropy = np.mean(attention_entropy)\n",
        "\n",
        "          # Ideal entropy range (empirically determined)\n",
        "          if 1.0 <= avg_entropy <= 3.0:\n",
        "              score = 1.0\n",
        "          elif avg_entropy < 1.0:\n",
        "              score = 0.7  # Too concentrated\n",
        "          else:\n",
        "              score = 0.8  # Too uniform\n",
        "      except:\n",
        "          score = 0.8  # Default if calculation fails\n",
        "\n",
        "      return score\n",
        "\n",
        "    def _generate_detailed_analysis(self, inchi: str, iupac: str, validation_result: Dict) -> Dict:\n",
        "      \"\"\"Generate detailed analysis of the prediction\"\"\"\n",
        "      analysis = {\n",
        "            'inchi_type': 'reconnected' if '/r' in inchi else 'standard',\n",
        "            'contains_metals': any(metal in inchi for metal in self.config.metal_elements),\n",
        "            'stereochemistry_present': bool(re.search(r'/[tms]', inchi)),\n",
        "            'coordination_complex': '/r' in inchi,\n",
        "            'iupac_length': len(iupac),\n",
        "            'validation_summary': {}\n",
        "        }\n",
        "\n",
        "      # Summarize validation scores\n",
        "      for key, score in validation_result['scores'].items():\n",
        "          if score < 0.5:\n",
        "              analysis['validation_summary'][key] = 'poor'\n",
        "          elif score < 0.8:\n",
        "              analysis['validation_summary'][key] = 'fair'\n",
        "          else:\n",
        "              analysis['validation_summary'][key] = 'good'\n",
        "\n",
        "      return analysis\n",
        "\n",
        "# Initialize validator\n",
        "validator = ChemicalValidator(config)\n",
        "\n",
        "# Test validation\n",
        "test_cases = [\n",
        "    {\n",
        "        'inchi': 'InChI=1/2C5H5.Fe/c2*1-2-4-5-3-1;/h2*1-5H;/rC10H10Fe/c1-2-4-8-6(1)11-7-3-1-5-9(7)10(11)12-8/h1-10H',\n",
        "        'predicted': 'bis(η⁵-cyclopentadienyl)iron'\n",
        "    },\n",
        "    {\n",
        "        'inchi': 'InChI=1S/C6H6/c1-2-4-6-5-3-1/h1-6H',\n",
        "        'predicted': 'benzene'\n",
        "    },\n",
        "    {\n",
        "        'inchi': 'InChI=1S/CH4/h1H4',\n",
        "        'predicted': '-----'\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"\\n Testing Enhanced Validation:\")\n",
        "for i, test_case in enumerate(test_cases, 1):\n",
        "    result = validator.validate_prediction(\n",
        "        test_case['inchi'],\n",
        "        test_case['predicted']\n",
        "    )\n",
        "    print(f\"\\nTest Case {i}:\")\n",
        "    print(f\"   Input: {test_case['predicted']}\")\n",
        "    print(f\"   Valid: {result['is_valid']}\")\n",
        "    print(f\"   Confidence: {result['confidence']:.3f}\")\n",
        "    print(f\"   Scores: {result['scores']}\")\n",
        "    if result['errors']:\n",
        "        print(f\"   Errors: {result['errors']}\")\n",
        "    if result['warnings']:\n",
        "        print(f\"   Warnings: {result['warnings']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_section"
      },
      "source": [
        "##  T5-Based METANO Model\n",
        "Pre-trained T5 model with chemical-aware tokenization and neurosymbolic integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_definition"
      },
      "outputs": [],
      "source": [
        "class ChemicalT5Tokenizer:\n",
        "    \"\"\"Enhanced T5 tokenizer for chemical data\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        self.config = config\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(self.config.model_name)\n",
        "\n",
        "        # Chemical-specific special tokens\n",
        "        self.special_tokens = [\n",
        "            '<STANDARD_INCHI>', '<RECONNECTED_INCHI>', '<ORGANIC>', '<INORGANIC>',\n",
        "            '<METAL>', '<LIGAND>', '<STEREO>', '<HAPTIC>', '<COORDINATION>',\n",
        "            '<CARBENE>', '<OXIDATION_STATE>', '<GEOMETRY>', '<ISOMER>',\n",
        "            '<FORMULA>', '<SYSTEMATIC>', '<TRIVIAL>'\n",
        "        ]\n",
        "\n",
        "        num_added = self.tokenizer.add_special_tokens({\n",
        "            'additional_special_tokens': self.special_tokens\n",
        "        })\n",
        "\n",
        "        logger.info(f\" Tokenizer initialized with {len(self.tokenizer)} tokens\")\n",
        "        logger.info(f\" Added {num_added} chemical-specific tokens\")\n",
        "\n",
        "        # Common ligands and functional groups\n",
        "        self.common_ligands = [\n",
        "            'cyclopentadienyl', 'carbonyl', 'phosphine', 'amine', 'aqua',\n",
        "            'chloro', 'bromo', 'fluoro', 'iodo', 'cyano', 'nitro', 'sulfo'\n",
        "        ]\n",
        "\n",
        "        # Stereochemical descriptors\n",
        "        self.stereo_descriptors = [\n",
        "            'cis', 'trans', 'fac', 'mer', 'syn', 'anti', 'endo', 'exo',\n",
        "            '(R)', '(S)', '(E)', '(Z)', '(+)', '(-)'\n",
        "        ]\n",
        "\n",
        "    def preprocess_inchi(self, inchi: str) -> str:\n",
        "        \"\"\"Preprocess InChI with chemical markers\"\"\"\n",
        "        processed = inchi\n",
        "\n",
        "        # Classify InChI type\n",
        "        if '/r' in inchi:\n",
        "            processed = '<RECONNECTED_INCHI> ' + processed\n",
        "        else:\n",
        "            processed = '<STANDARD_INCHI> ' + processed\n",
        "\n",
        "        # Detect metal marks\n",
        "        metals_found = [metal for metal in self.config.metal_elements if metal in processed]\n",
        "        if metals_found:\n",
        "            # Mark the first metal found\n",
        "            primary_metal = metals_found[0]\n",
        "            processed = processed.replace(primary_metal, f'<METAL> {primary_metal}', 1)\n",
        "\n",
        "            # Classify as inorganic if metals are present\n",
        "            if '<ORGANIC>' not in processed:\n",
        "                processed = processed.replace('<STANDARD_INCHI>', '<INORGANIC> <STANDARD_INCHI>')\n",
        "                processed = processed.replace('<RECONNECTED_INCHI>', '<INORGANIC> <RECONNECTED_INCHI>')\n",
        "        else:\n",
        "            # Mark as organic\n",
        "            processed = '<ORGANIC> ' + processed\n",
        "\n",
        "        # Mark stereochemistry indicators\n",
        "        stereo_patterns = ['@', '/', '\\\\']  # Fixed escape sequence\n",
        "        if any(pattern in processed for pattern in stereo_patterns):\n",
        "            processed = '<STEREO> ' + processed\n",
        "\n",
        "        return processed\n",
        "\n",
        "    def preprocess_iupac(self, iupac: str) -> str:\n",
        "        \"\"\"Preprocess IUPAC with chemical markers\"\"\"\n",
        "        processed = iupac.lower()\n",
        "        original_iupac = iupac\n",
        "\n",
        "        # Mark systematic vs trivial names\n",
        "        systematic_indicators = ['yl', 'ane', 'ene', 'yne', 'oyl', 'ate', 'ide']\n",
        "        if any(indicator in processed for indicator in systematic_indicators):\n",
        "            processed = '<SYSTEMATIC> ' + original_iupac\n",
        "        else:\n",
        "            processed = '<TRIVIAL> ' + original_iupac\n",
        "\n",
        "        # Mark stereochemical descriptors\n",
        "        for stereo in self.stereo_descriptors:\n",
        "            if stereo.lower() in processed:\n",
        "                processed = processed.replace(stereo.lower(), f'<STEREO> {stereo}', 1)\n",
        "                break\n",
        "\n",
        "        # Mark haptic notation (η1, η2, etc.)\n",
        "        haptic_pattern = re.compile(r'η[¹²³⁴⁵⁶⁷⁸⁹⁰\\d]+')\n",
        "        if haptic_pattern.search(original_iupac):\n",
        "            processed = '<HAPTIC> ' + processed\n",
        "\n",
        "        # Mark coordination compounds\n",
        "        coordination_indicators = ['bis', 'tris', 'tetrakis', 'pentakis', 'hexakis']\n",
        "        if any(indicator in processed for indicator in coordination_indicators):\n",
        "            processed = '<COORDINATION> ' + processed\n",
        "\n",
        "        # Mark oxidation states\n",
        "        oxidation_pattern = re.compile(r'\\([IVX]+\\)|\\(\\d+[+-]\\)')  # Fixed escape sequences\n",
        "        if oxidation_pattern.search(original_iupac):\n",
        "            processed = '<OXIDATION_STATE> ' + processed\n",
        "\n",
        "        return processed\n",
        "\n",
        "    def encode(self, text: str, max_length: int, is_target: bool = False) -> Dict:\n",
        "        \"\"\"Encode text with attention to chemical tokens\"\"\"\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze()\n",
        "        }\n",
        "\n",
        "    def decode(self, token_ids: torch.Tensor, skip_special_tokens: bool = True) -> str:\n",
        "        \"\"\"Decode tokens to text with chemical token cleanup\"\"\"\n",
        "        if isinstance(token_ids, torch.Tensor):\n",
        "          token_ids = token_ids.cpu().numpy()\n",
        "\n",
        "        decoded = self.tokenizer.decode(token_ids, skip_special_tokens=True)\n",
        "\n",
        "        # Remove chemical special token for clean output\n",
        "        if skip_special_tokens:\n",
        "            for token in self.special_tokens:\n",
        "              decoded = decoded.replace(token, '').strip()\n",
        "\n",
        "        # Clean-up extra space\n",
        "        decoded = ' '.join(decoded.split())\n",
        "\n",
        "        return decoded\n",
        "\n",
        "    def get_vocab_size(self) -> int:\n",
        "        \"\"\"Get total vocabulary size including special tokens\"\"\"\n",
        "        return len(self.tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVRqn5doEYYb"
      },
      "outputs": [],
      "source": [
        "class MetanoDataset(Dataset):\n",
        "    \"\"\"PyTorch dataset for InChI-IUPAC pairs\"\"\"\n",
        "\n",
        "    def __init__(self, data: List[Tuple[str, str]], tokenizer: ChemicalT5Tokenizer, config: ModelConfig):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inchi, iupac = self.data[idx]\n",
        "\n",
        "        # Preprocess\n",
        "        processed_inchi = self.tokenizer.preprocess_inchi(inchi)\n",
        "        processed_iupac = self.tokenizer.preprocess_iupac(iupac)\n",
        "\n",
        "        # Encode input and target\n",
        "        input_encoding = self.tokenizer.encode(processed_inchi, self.config.max_input_length)\n",
        "        target_encoding = self.tokenizer.encode(processed_iupac, self.config.max_output_length, is_target=True)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encoding['input_ids'],\n",
        "            'attention_mask': input_encoding['attention_mask'],\n",
        "            'labels': target_encoding['input_ids']\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TYwBPSkdC3D"
      },
      "outputs": [],
      "source": [
        "class MetanoModel(nn.Module):\n",
        "    \"\"\"T5-based InChI to IUPAC name translation model\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Initialize tokenizer and model\n",
        "        self.tokenizer = ChemicalT5Tokenizer(config)\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(config.model_name)\n",
        "\n",
        "        # Resize embeddings for new tokens\n",
        "        self.model.resize_token_embeddings(self.tokenizer.get_vocab_size())\n",
        "\n",
        "        # Initaliza checkpoint manager\n",
        "        self.checkpoint_manager = CheckpointManager(config)\n",
        "\n",
        "        # Training state\n",
        "        self.current_epoch = 0\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.training_history = {\n",
        "            'train_loss': [],\n",
        "            'val_loss': [],\n",
        "            'learning_rates': [],\n",
        "            'epochs': [],\n",
        "            'metrics': []\n",
        "        }\n",
        "\n",
        "        # Initialize validator\n",
        "        self.validator = ChemicalValidator(config)\n",
        "\n",
        "        logger.info(f\" Enhanced model initialized: {config.model_name}\")\n",
        "        logger.info(f\" Parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
        "        logger.info(f\" Vocabulary size: {self.tokenizer.get_vocab_size()}\")\n",
        "\n",
        "        # Auto-resume from checkpoint available\n",
        "        if config.auto_resume:\n",
        "          self.resume_from_checkpoint(from_gdrive=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        return self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "    def predict(self, inchi: str, validate: bool = True) -> Dict:\n",
        "        \"\"\"Predict IUPAC name with optional validation\"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Preprocess and encode\n",
        "            processed_inchi = self.tokenizer.preprocess_inchi(inchi)\n",
        "            encoding = self.tokenizer.encode(processed_inchi, self.config.max_input_length)\n",
        "\n",
        "            # Move to device\n",
        "            input_ids = encoding['input_ids'].unsqueeze(0).to(device)\n",
        "            attention_mask = encoding['attention_mask'].unsqueeze(0).to(device)\n",
        "\n",
        "            # Generate multiple predictions\n",
        "            outputs = self.model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=self.config.max_output_length,\n",
        "                num_beams=self.config.num_beams,\n",
        "                num_return_sequences=self.config.num_beams,  # Generate num_beams predictions\n",
        "                do_sample=self.config.do_sample,\n",
        "                temperature=self.config.temperature,\n",
        "                early_stopping=True,\n",
        "                pad_token_id=self.tokenizer.tokenizer.pad_token_id,\n",
        "                eos_token_id=self.tokenizer.tokenizer.eos_token_id,\n",
        "            )\n",
        "\n",
        "            # Decode and validate each prediction\n",
        "            best_prediction = None\n",
        "            highest_confidence = -1.0\n",
        "\n",
        "            for output_sequence in outputs:\n",
        "                predicted_iupac = self.tokenizer.decode(output_sequence, skip_special_tokens=True)\n",
        "\n",
        "                validation_result = None\n",
        "                if validate:\n",
        "                    validation_result = self.validator.validate_prediction(inchi, predicted_iupac)\n",
        "\n",
        "                prediction_info = {\n",
        "                    'inchi': inchi,\n",
        "                    'predicted_iupac': predicted_iupac,\n",
        "                    'validation': validation_result\n",
        "                }\n",
        "\n",
        "                # Track the best prediction based on confidence\n",
        "                if validation_result and validation_result['confidence'] > highest_confidence:\n",
        "                    highest_confidence = validation_result['confidence']\n",
        "                    best_prediction = prediction_info\n",
        "\n",
        "            return best_prediction # Return the prediction with the highest confidence\n",
        "\n",
        "    def resume_from_checkpoint(self, checkpoint_path: str = None, from_gdrive: bool = False) -> bool:\n",
        "        \"\"\"Resume training from checkpoint with full state restoration\"\"\"\n",
        "        checkpoint_data = self.checkpoint_manager.load_checkpoint(checkpoint_path, from_gdrive)\n",
        "\n",
        "        if checkpoint_data is None:\n",
        "            logger.info(\" No checkpoint found for resuming\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Load model state\n",
        "            self.model.load_state_dict(checkpoint_data['model_state_dict'])\n",
        "\n",
        "            # Restore training state\n",
        "            self.current_epoch = checkpoint_data.get('epoch', 0)\n",
        "            self.best_val_loss = checkpoint_data.get('loss', float('inf'))\n",
        "\n",
        "            # Restore training history if available\n",
        "            if 'training_history' in checkpoint_data:\n",
        "                self.training_history = checkpoint_data['training_history']\n",
        "\n",
        "            logger.info(f\" Successfully resumed from checkpoint\")\n",
        "            logger.info(f\" Resumed at epoch: {self.current_epoch}\")\n",
        "            logger.info(f\" Best validation loss: {self.best_val_loss:.4f}\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Failed to resume from checkpoint: {e}\")\n",
        "            return False\n",
        "\n",
        "    def save_checkpoint(self, optimizer, scheduler, epoch: int, loss: float,\n",
        "                        metrics: Dict = None, is_best: bool = False) -> str:\n",
        "\n",
        "        \"\"\"Save model checkpoint with metadata\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "\n",
        "        if is_best:\n",
        "          self.best_val_loss = loss\n",
        "\n",
        "        # Update training history\n",
        "        self.training_history['epochs'].append(epoch)\n",
        "        if metrics:\n",
        "          self.training_history['metrics'].append(metrics)\n",
        "\n",
        "        return self.checkpoint_manager.save_checkpoint(\n",
        "            self.model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            epoch,\n",
        "            loss,\n",
        "            metrics,\n",
        "            is_best\n",
        "        )\n",
        "\n",
        "    def get_model_summary(self) -> Dict:\n",
        "        \"\"\"Get comprehensive model summary\"\"\"\n",
        "        total_params = sum(p.numel() for p in self.model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "\n",
        "        return {\n",
        "            'model_name': self.config.model_name,\n",
        "            'total_parameters': total_params,\n",
        "            'trainable_parameters': trainable_params,\n",
        "            'vocabulary_size': self.tokenizer.get_vocab_size(),\n",
        "            'current_epoch': self.current_epoch,\n",
        "            'best_val_loss': self.best_val_loss,\n",
        "            'training_history_length': len(self.training_history['epochs']),\n",
        "            'device': str(device),\n",
        "            'checkpoint_summary': self.checkpoint_manager.get_checkpoint_summary()\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "##  Model Training and Optimization\n",
        "Train the model with optimized hyperparameters and early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 452,
          "referenced_widgets": [
            "027a20b226fc4de3b12a0424ddc6a7f8",
            "8d7a9d8b420d4c53a76b2e9bd5c47060",
            "95d955e30f7647f683111f5d33b3b286",
            "52c95b1bb15c4474b0fa266da894920a",
            "8726c8c745df424a9c2b790b27b04d5f",
            "8e88f21c88624dffaca64e22e76b9a50",
            "d44fc5671aa8452a854b11afc46fc180",
            "5596e74309fa4107a2bcfd20085b6aee",
            "c3946d463a7a4dc5a75e046b894e9225",
            "641998b1cd9b403e9e68e9069a22ab0b",
            "70a1f93355794637a334178ae5eb9e99",
            "1c34cae4ac6b47b4b519b5f89cbddde1",
            "b0223bdee29a4adf9c97c67cc17a7cad",
            "bd979610c163426cb3a692c29a41f011",
            "bae2d4227e1344b083cfb26156156034",
            "ae7943aab0a446dbb43f895cc897e3f5",
            "c1bdb55ef08c4f3fa2c599843150ecb5",
            "e195ad1e287d4eac9eb289d4a0d96bf3",
            "2de70ed185ca4b0c942e0392e6a4f893",
            "5cb28d145acd4735ac2b8158346ffc87",
            "1213615a4a654d489fe0209940289489",
            "6a9672aa70164030a4aa09d548fb2cfd",
            "f6a8f19803424a378b2865736f4db54c",
            "7a1676af438f4d0ab28a2f38c3238422",
            "de1e0063323a49b8bbc91b6069183827",
            "1c75aeea824f446ba6e0e563075ad70c",
            "7dd7724eae094afa921fb30805e6333c",
            "1d21ebd096f14c098362e132f46b5653",
            "678fc17633954649914c82f3ab47bd8f",
            "7307937e13b243aeb33af5e9ca27c856",
            "0ab4246874b24ff5b5b79fa22727a7c3",
            "3fd223289a9846ccb7473b6c9c22c7e5",
            "2101e059e88b4b9298cdfed14a910df2",
            "da3c022c494b42788d8cc99ceefc2d16",
            "e2564281e6244b5180bd2b8629470678",
            "f437496339284ebd92d2b717679abd6a",
            "238f929bf4084db3acfb1df7124254ec",
            "73e87ca35f574dc5818a519d58d3d558",
            "239ee360fe174c75992aef0c81d45342",
            "58ec0710dd0a457bb598ffd6552c1a30",
            "e9d6d9b0556d4a47a8d45840d41dade0",
            "be8dc65fb5cb4694b31c9e14dd94701f",
            "5b23ce4665f2468592937664eba5d513",
            "6d712f99b5b740b28005a125d5cee619",
            "b15c2f4b737449f49a270a5548f95c88",
            "c66e77dc32d14070a0987e41e6ae79d0",
            "714de1272a654f6aa87f2d8ae3a5a10f",
            "04783ef6a9e54a2b9f426e83b33d657f",
            "0884827c2e624d6c843bd3c6a578740a",
            "13d17dea6e7f42ef999d414c0c5ed05b",
            "9add9c82ae554e61a6f44b79e2a422be",
            "7c460946728f48c9927d6748e8b900c2",
            "f64a35e01f124ebaa56f6a5e38604f9f",
            "3b6330d8188341d3a2620862f242a09a",
            "131bffb067d24fe28ebf0beea4271fd1",
            "54809ed57ec74af48b13990227683d6c",
            "089211fa967a42b7b3e6c16bdddf674c",
            "e7f4f4cb7834484faf2534dbf15a8542",
            "ecaacfaa711948fa8e56d3d41ac0bdfd",
            "0496301f985148baacb14c7d713b3a1f",
            "2f4eb4558b7e4b748a10f6d15001802f",
            "853a77cb5a9e4d9da75e189eb72601a2",
            "a048d60c17574124af16db8b0dca9894",
            "f4dd0782cc9c46a1bb41b01dd580a5f4",
            "1c4fe07087e1469f8224a4f714b7af49",
            "4204953d974246048d2ec2525448ccd9",
            "b276a6c1378648098bce3ab305a28974",
            "3f49118e83d34a598d8a09418be14654",
            "8e69a06be0da49678a546a2242856ea9",
            "5cd13f741eac4dcf9d2b00d1b7756a30",
            "e224e162e47f48dea60739b8d5378d9b",
            "4bf864449e644c4b9a0d54b17b98fca1",
            "ce3e5c81704b41afb56e5291363a7062",
            "874d4c49068d4bf8a1946261f605cc27",
            "d99cb88ce1624eb18176b64a41db9dfa",
            "7a6e2ac10322497aab4178c4a6fb9346",
            "e754e491b69a4ebda5014d8d21a5155b"
          ]
        },
        "id": "training_functions",
        "outputId": "0a8ef8eb-620d-4a54-cfd4-d39ffad9b670"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "027a20b226fc4de3b12a0424ddc6a7f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c34cae4ac6b47b4b519b5f89cbddde1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6a8f19803424a378b2865736f4db54c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da3c022c494b42788d8cc99ceefc2d16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b15c2f4b737449f49a270a5548f95c88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54809ed57ec74af48b13990227683d6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model Summary:\n",
            "  Total parameters: 60,500,480\n",
            "  Trainable parameters: 60,500,480\n",
            "  Vocabulary size: 32,116\n",
            "  Current epoch: 3\n",
            "\n",
            " Dataset split:\n",
            "   Train: 47446 pairs\n",
            "   Validation: 13556 pairs\n",
            "   Test: 6779 pairs\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b276a6c1378648098bce3ab305a28974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5/20:   0%|          | 0/11861 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def split_dataset(data: List[Tuple[str, str]], config: ModelConfig):\n",
        "    \"\"\"Split dataset into train/val/test sets\"\"\"\n",
        "    random.shuffle(data)\n",
        "\n",
        "    total_size = len(data)\n",
        "    train_size = int(total_size * config.train_split)\n",
        "    val_size = int(total_size * config.val_split)\n",
        "\n",
        "    train_data = data[:train_size]\n",
        "    val_data = data[train_size:train_size + val_size]\n",
        "    test_data = data[train_size + val_size:]\n",
        "\n",
        "    print(f\"\\n Dataset split:\")\n",
        "    print(f\"   Train: {len(train_data)} pairs\")\n",
        "    print(f\"   Validation: {len(val_data)} pairs\")\n",
        "    print(f\"   Test: {len(test_data)} pairs\")\n",
        "\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "def create_data_loaders(train_data, val_data, model, config):\n",
        "    \"\"\"Create PyTorch data loaders\"\"\"\n",
        "    def collate_fn(batch):\n",
        "        return {\n",
        "            'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
        "            'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
        "            'labels': torch.stack([item['labels'] for item in batch])\n",
        "        }\n",
        "\n",
        "    train_dataset = MetanoDataset(train_data, model.tokenizer, config)\n",
        "    val_dataset = MetanoDataset(val_data, model.tokenizer, config) if val_data else None\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    val_loader = None\n",
        "    if val_dataset:\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=False,\n",
        "            collate_fn=collate_fn,\n",
        "            num_workers=0,\n",
        "            drop_last=False\n",
        "        )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def train_model(model, train_loader, val_loader, config):\n",
        "    \"\"\"Train the model with optimized settings\"\"\"\n",
        "    logger.info(\" Starting model training...\")\n",
        "\n",
        "    # Setup optimizer and scheduler\n",
        "    optimizer = optim.AdamW(\n",
        "        model.model.parameters(),\n",
        "        lr=config.learning_rate,\n",
        "        weight_decay=config.weight_decay,\n",
        "        eps=1e-8,\n",
        "        betas=(0.9, 0.999)\n",
        "    )\n",
        "\n",
        "    steps_per_epoch = len(train_loader) // config.gradient_accumulation_steps\n",
        "    total_steps = steps_per_epoch * config.num_epochs\n",
        "    warmup_steps = int(total_steps * config.warmup_ratio)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    start_epoch = (model.current_epoch + 1)\n",
        "    best_val_loss = model.best_val_loss\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Load optimizer state and scheduler state if resuming\n",
        "    if start_epoch > 0:\n",
        "      checkpoint_data = model.checkpoint_manager.load_checkpoint()\n",
        "      if checkpoint_data:\n",
        "        if 'optimizer_state_dict' in checkpoint_data:\n",
        "                optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])\n",
        "                logger.info(\" Optimizer state restored\")\n",
        "        if 'scheduler_state_dict' in checkpoint_data and checkpoint_data['scheduler_state_dict']:\n",
        "            scheduler.load_state_dict(checkpoint_data['scheduler_state_dict'])\n",
        "            logger.info(\" Scheduler state restored\")\n",
        "\n",
        "    logger.info(f\" Training configuration:\")\n",
        "    logger.info(f\"   Total steps: {total_steps}\")\n",
        "    logger.info(f\"   Warmup steps: {warmup_steps}\")\n",
        "    logger.info(f\"   Learning rate: {config.learning_rate}\")\n",
        "    logger.info(f\"   Batch size: {config.batch_size}\")\n",
        "\n",
        "    for epoch in range(start_epoch, config.num_epochs):\n",
        "        # Training phase\n",
        "        model.model.train()\n",
        "        train_loss = 0\n",
        "        train_steps = 0\n",
        "\n",
        "        progress_bar = tqdm(\n",
        "            train_loader,\n",
        "            desc=f\"Epoch {epoch+1}/{config.num_epochs}\",\n",
        "            leave=False\n",
        "        )\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss / config.gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient accumulation\n",
        "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(model.model.parameters(), 1.0)\n",
        "\n",
        "                #  Optimizer step\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            train_loss += loss.item() * config.gradient_accumulation_steps\n",
        "            train_steps += 1\n",
        "\n",
        "            # Update progress bar\n",
        "            current_lr = scheduler.get_last_lr()[0] if scheduler.get_last_lr() else config.learning_rate\n",
        "            progress_bar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'LR': f'{current_lr:.2e}'\n",
        "            })\n",
        "\n",
        "        # Calculate average training loss\n",
        "        avg_train_loss = train_loss / max(train_steps, 1)\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss = float('inf')\n",
        "        if val_loader:\n",
        "            model.model.eval()\n",
        "            total_val_loss = 0\n",
        "            val_steps = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['labels'].to(device)\n",
        "\n",
        "                    outputs = model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        labels=labels\n",
        "                    )\n",
        "\n",
        "                    total_val_loss += outputs.loss.item()\n",
        "                    val_steps += 1\n",
        "\n",
        "        val_loss = total_val_loss / max(val_steps, 1)\n",
        "        model.training_history['val_loss'].append(val_loss)\n",
        "        model.training_history['train_loss'].append(avg_train_loss)\n",
        "        model.training_history['learning_rates'].append(current_lr)\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        metrics = {\n",
        "            'train_loss': avg_train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'learning_rate': current_lr,\n",
        "            'epoch': epoch + 1,\n",
        "            'total_steps': (epoch + 1) * len(train_loader),\n",
        "            'patience_counter': patience_counter\n",
        "        }\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\n Epoch {epoch+1} Summary:\")\n",
        "        print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
        "        if val_loader:\n",
        "            print(f\"   Val Loss: {val_loss:.4f}\")\n",
        "        print(f\"   Learning Rate: {current_lr:.2e}\")\n",
        "        print(f\"   Improvement: {(best_val_loss - val_loss):.6f}\")\n",
        "\n",
        "        # Check for improvement\n",
        "        is_best = val_loss < best_val_loss\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % config.checkpoint_frequency == 0 or is_best:\n",
        "            checkpoint_path = model.save_checkpoint(\n",
        "                optimizer, scheduler, epoch, val_loss, metrics, is_best\n",
        "            )\n",
        "\n",
        "            if is_best:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                print(f\" New best model saved (Val Loss: {val_loss:.6f}\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                print(f\" Checkpoint saved: {os.path.basename(checkpoint_path)}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        logger.info(f\" Patience: {patience_counter}/{config.early_stopping_patience}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if patience_counter >= config.early_stopping_patience:\n",
        "            print(f\" Early stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    print(\" Training completed!\")\n",
        "    return model.training_history\n",
        "\n",
        "# Initialize model\n",
        "logger.info(\" Initializing the model...\")\n",
        "model = MetanoModel(config)\n",
        "model.to(device)\n",
        "\n",
        "# Display model summary\n",
        "summary = model.get_model_summary()\n",
        "print(f\" Model Summary:\")\n",
        "print(f\"  Total parameters: {summary['total_parameters']:,}\")\n",
        "print(f\"  Trainable parameters: {summary['trainable_parameters']:,}\")\n",
        "print(f\"  Vocabulary size: {summary['vocabulary_size']:,}\")\n",
        "print(f\"  Current epoch: {summary['current_epoch']}\")\n",
        "\n",
        "\n",
        "# Split dataset\n",
        "train_data, val_data, test_data = split_dataset(data, config)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader, val_loader = create_data_loaders(train_data, val_data, model, config)\n",
        "\n",
        "# Train the model\n",
        "training_history = train_model(model, train_loader, val_loader, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_section"
      },
      "source": [
        "##  Model Evaluation and Accuracy Calculation\n",
        "Comprehensive evaluation with multiple metrics including BLEU, exact match, and chemical validity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluation_functions"
      },
      "outputs": [],
      "source": [
        "class ModelEvaluator:\n",
        "    \"\"\"Comprehensive model evaluation system\"\"\"\n",
        "\n",
        "    def __init__(self, model, validator):\n",
        "        self.model = model\n",
        "        self.validator = validator\n",
        "\n",
        "    def evaluate_on_test_set(self, test_data: List[Tuple[str, str]]) -> Dict:\n",
        "        \"\"\"Evaluate model on test dataset\"\"\"\n",
        "        print(\" Starting comprehensive evaluation...\")\n",
        "\n",
        "        results = {\n",
        "            'predictions': [],\n",
        "            'metrics': {\n",
        "                'exact_match': 0.0,\n",
        "                'bleu_score': 0.0,\n",
        "                'chemical_validity': 0.0,\n",
        "                'grammar_score': 0.0,\n",
        "                'metal_consistency': 0.0,\n",
        "                'confidence_score': 0.0\n",
        "            },\n",
        "            'by_category': {\n",
        "                'organic': {'count': 0, 'exact_match': 0, 'bleu': 0},\n",
        "                'organometallic': {'count': 0, 'exact_match': 0, 'bleu': 0},\n",
        "                'standard_inchi': {'count': 0, 'exact_match': 0, 'bleu': 0},\n",
        "                'reconnected_inchi': {'count': 0, 'exact_match': 0, 'bleu': 0}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        exact_matches = 0\n",
        "        total_bleu = 0\n",
        "        total_grammar_score = 0\n",
        "        total_metal_coordination = 0\n",
        "        total_stereo_score = 0\n",
        "        total_structure_score = 0\n",
        "        total_nomenclature_score = 0\n",
        "        total_attention_score = 0\n",
        "        total_confidence = 0\n",
        "\n",
        "        self.model.model.eval()\n",
        "\n",
        "        for i, (inchi, true_iupac) in enumerate(tqdm(test_data, desc=\"Evaluating\")):\n",
        "            # Get prediction\n",
        "            prediction_result = self.model.predict(inchi, validate=True)\n",
        "            predicted_iupac = prediction_result['predicted_iupac']\n",
        "            validation = prediction_result['validation']\n",
        "\n",
        "            # Calculate metrics\n",
        "            is_exact_match = self._is_exact_match(predicted_iupac, true_iupac)\n",
        "            bleu = self._calculate_bleu(predicted_iupac, true_iupac)\n",
        "\n",
        "            # Aggregate metrics\n",
        "            if is_exact_match:\n",
        "                exact_matches += 1\n",
        "\n",
        "            total_bleu += bleu\n",
        "            total_grammar_score += validation['scores']['grammar']\n",
        "            total_metal_coordination += validation['scores']['metal_coordination']\n",
        "            total_stereo_score += validation['scores']['stereochemistry']\n",
        "            total_structure_score += validation['scores']['structure_consistency']\n",
        "            total_nomenclature_score += validation['scores']['nomenclature']\n",
        "            total_attention_score += validation['scores']['attention_quality']\n",
        "            total_confidence += validation['confidence']\n",
        "\n",
        "            # Categorize results\n",
        "            self._categorize_result(inchi, predicted_iupac, true_iupac, is_exact_match, bleu, results)\n",
        "\n",
        "            # Store detailed results\n",
        "            results['predictions'].append({\n",
        "                'inchi': inchi,\n",
        "                'true_iupac': true_iupac,\n",
        "                'predicted_iupac': predicted_iupac,\n",
        "                'exact_match': is_exact_match,\n",
        "                'bleu_score': bleu,\n",
        "                'validation': validation\n",
        "            })\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        n_samples = len(test_data)\n",
        "        results['metrics']['exact_match'] = exact_matches / n_samples\n",
        "        results['metrics']['bleu_score'] = total_bleu / n_samples\n",
        "        results['metrics']['chemical_validity'] = total_structure_score / n_samples\n",
        "        results['metrics']['grammar_score'] = total_grammar_score / n_samples\n",
        "        results['metrics']['metal_coordination'] = total_metal_coordination / n_samples\n",
        "        results['metrics']['confidence_score'] = total_confidence / n_samples\n",
        "\n",
        "        # Calculate category-specific metrics\n",
        "        for category, stats in results['by_category'].items():\n",
        "            if stats['count'] > 0:\n",
        "                stats['exact_match'] = stats['exact_match'] / stats['count']\n",
        "                stats['bleu'] = stats['bleu'] / stats['count']\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _is_exact_match(self, predicted: str, true: str) -> bool:\n",
        "        \"\"\"Check if prediction exactly matches true value\"\"\"\n",
        "        return predicted.strip().lower() == true.strip().lower()\n",
        "\n",
        "    def _calculate_bleu(self, predicted: str, true: str) -> float:\n",
        "        \"\"\"Calculate BLEU score\"\"\"\n",
        "        try:\n",
        "            # Handle edge cases\n",
        "            if not predicted or not true:\n",
        "                return 0.0\n",
        "\n",
        "            # Clean and tokenize\n",
        "            predicted_tokens = predicted.strip().lower().split()\n",
        "            true_tokens = true.strip().lower().split()\n",
        "\n",
        "            if not predicted_tokens or not true_tokens:\n",
        "                return 0.0\n",
        "\n",
        "            # NLTK expects references as list of lists\n",
        "            reference_list = [true_tokens]\n",
        "\n",
        "            # Use smoothing to avoid zero scores\n",
        "            smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "            # Calculate BLEU with smoothing\n",
        "            bleu_score = sentence_bleu(\n",
        "                reference_list,\n",
        "                predicted_tokens,\n",
        "                smoothing_function=smoothing_function\n",
        "            )\n",
        "\n",
        "            return max(0.0, min(1.0, bleu_score))\n",
        "\n",
        "        except Exception:\n",
        "            return 0.0\n",
        "\n",
        "    def _categorize_result(self, inchi: str, predicted: str, true: str,\n",
        "                          exact_match: bool, bleu: float, results: Dict):\n",
        "        \"\"\"Categorize results by molecule type and InChI format\"\"\"\n",
        "        # Check if organometallic\n",
        "        metals = ['Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Mn', 'Cr', 'Pt', 'Pd']\n",
        "        is_organometallic = any(metal in inchi for metal in metals)\n",
        "\n",
        "        # Check InChI format\n",
        "        is_standard = 'InChI=1S/' in inchi\n",
        "        is_reconnected = '/r' in inchi\n",
        "\n",
        "        # Update category statistics\n",
        "        if is_organometallic:\n",
        "            results['by_category']['organometallic']['count'] += 1\n",
        "            if exact_match:\n",
        "                results['by_category']['organometallic']['exact_match'] += 1\n",
        "            results['by_category']['organometallic']['bleu'] += bleu\n",
        "        else:\n",
        "            results['by_category']['organic']['count'] += 1\n",
        "            if exact_match:\n",
        "                results['by_category']['organic']['exact_match'] += 1\n",
        "            results['by_category']['organic']['bleu'] += bleu\n",
        "\n",
        "        if is_standard:\n",
        "            results['by_category']['standard_inchi']['count'] += 1\n",
        "            if exact_match:\n",
        "                results['by_category']['standard_inchi']['exact_match'] += 1\n",
        "            results['by_category']['standard_inchi']['bleu'] += bleu\n",
        "        elif is_reconnected:\n",
        "            results['by_category']['reconnected_inchi']['count'] += 1\n",
        "            if exact_match:\n",
        "                results['by_category']['reconnected_inchi']['exact_match'] += 1\n",
        "            results['by_category']['reconnected_inchi']['bleu'] += bleu\n",
        "\n",
        "    def generate_evaluation_report(self, results: Dict) -> str:\n",
        "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
        "        report = []\n",
        "        report.append(\" MODEL EVALUATION REPORT\")\n",
        "        report.append(\"=\" * 50)\n",
        "\n",
        "        # Overall metrics\n",
        "        metrics = results['metrics']\n",
        "        report.append(f\"\\n Overall Performance:\")\n",
        "        report.append(f\"   Exact Match Accuracy: {metrics['exact_match']:.3f} ({metrics['exact_match']*100:.1f}%)\")\n",
        "        report.append(f\"   BLEU Score: {metrics['bleu_score']:.3f}\")\n",
        "        report.append(f\"   Chemical Validity: {metrics['chemical_validity']:.3f}\")\n",
        "        report.append(f\"   Grammar Score: {metrics['grammar_score']:.3f}\")\n",
        "        report.append(f\"   Metal Consistency: {metrics['metal_consistency']:.3f}\")\n",
        "        report.append(f\"   Confidence Score: {metrics['confidence_score']:.3f}\")\n",
        "\n",
        "        # Performance by category\n",
        "        report.append(f\"\\n Performance by Category:\")\n",
        "        for category, stats in results['by_category'].items():\n",
        "            if stats['count'] > 0:\n",
        "                report.append(f\"   {category.replace('_', ' ').title()}:\")\n",
        "                report.append(f\"     Count: {stats['count']}\")\n",
        "                report.append(f\"     Exact Match: {stats['exact_match']:.3f} ({stats['exact_match']*100:.1f}%)\")\n",
        "                report.append(f\"     BLEU Score: {stats['bleu']:.3f}\")\n",
        "\n",
        "        # Sample predictions\n",
        "        report.append(f\"\\n Sample Predictions:\")\n",
        "        for i, pred in enumerate(results['predictions'][:5]):\n",
        "            status = \"✅\" if pred['exact_match'] else \"❌\"\n",
        "            report.append(f\"   {i+1}. {status} {pred['true_iupac']} → {pred['predicted_iupac']}\")\n",
        "            report.append(f\"      BLEU: {pred['bleu_score']:.3f}, Confidence: {pred['validation']['confidence']:.3f}\")\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "logger.info(\" Starting model evaluation...\")\n",
        "evaluator = ModelEvaluator(model, validator)\n",
        "evaluation_results = evaluator.evaluate_on_test_set(test_data)\n",
        "\n",
        "# Generate and display report\n",
        "report = evaluator.generate_evaluation_report(evaluation_results)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_section"
      },
      "source": [
        "##  Visualization and Analysis\n",
        "Visualize training progress and evaluation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualization_code"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(training_history):\n",
        "    \"\"\"Plot training and validation loss curves\"\"\"\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    epochs = range(1, len(training_history['train_loss']) + 1)\n",
        "\n",
        "    # Training and validation loss\n",
        "    ax1.plot(epochs, training_history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
        "    if training_history['val_loss']:\n",
        "        ax1.plot(epochs, training_history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Learning rate schedule\n",
        "    ax2.plot(epochs, training_history['learning_rates'], 'g-', linewidth=2)\n",
        "    ax2.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Learning Rate')\n",
        "    ax2.set_yscale('log')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Model performance metrics\n",
        "    metrics_names = ['Exact Match', 'BLEU Score', 'Chemical Validity', 'Grammar Score']\n",
        "    metrics_values = [\n",
        "        evaluation_results['metrics']['exact_match'],\n",
        "        evaluation_results['metrics']['bleu_score'],\n",
        "        evaluation_results['metrics']['chemical_validity'],\n",
        "        evaluation_results['metrics']['grammar_score']\n",
        "    ]\n",
        "\n",
        "    bars = ax3.bar(metrics_names, metrics_values, color=['skyblue', 'lightgreen', 'orange', 'pink'])\n",
        "    ax3.set_title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
        "    ax3.set_ylabel('Score')\n",
        "    ax3.set_ylim(0, 1)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, metrics_values):\n",
        "        height = bar.get_height()\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # Performance by category\n",
        "    categories = []\n",
        "    accuracies = []\n",
        "\n",
        "    for category, stats in evaluation_results['by_category'].items():\n",
        "        if stats['count'] > 0:\n",
        "            categories.append(category.replace('_', '\\n').title())\n",
        "            accuracies.append(stats['exact_match'])\n",
        "\n",
        "    if categories:\n",
        "        bars = ax4.bar(categories, accuracies, color=['lightcoral', 'lightblue', 'lightgreen', 'gold'])\n",
        "        ax4.set_title('Accuracy by Category', fontsize=14, fontweight='bold')\n",
        "        ax4.set_ylabel('Exact Match Accuracy')\n",
        "        ax4.set_ylim(0, 1)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar, value in zip(bars, accuracies):\n",
        "            height = bar.get_height()\n",
        "            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        plt.xticks(rotation=45)\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def create_prediction_examples_table(results):\n",
        "    \"\"\"Create a detailed table of prediction examples\"\"\"\n",
        "    print(\"\\n DETAILED PREDICTION EXAMPLES\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    # Create DataFrame for better display\n",
        "    examples_data = []\n",
        "\n",
        "    for i, pred in enumerate(results['predictions'][:10]):\n",
        "        examples_data.append({\n",
        "            'ID': i + 1,\n",
        "            'True IUPAC': pred['true_iupac'][:30] + '...' if len(pred['true_iupac']) > 30 else pred['true_iupac'],\n",
        "            'Predicted IUPAC': pred['predicted_iupac'][:30] + '...' if len(pred['predicted_iupac']) > 30 else pred['predicted_iupac'],\n",
        "            'Match': '✅' if pred['exact_match'] else '❌',\n",
        "            'BLEU': f\"{pred['bleu_score']:.3f}\",\n",
        "            'Confidence': f\"{pred['validation']['confidence']:.3f}\",\n",
        "            'Valid': '✅' if pred['validation']['is_valid'] else '❌'\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(examples_data)\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "# Generate visualizations\n",
        "print(\" Generating visualizations...\")\n",
        "plot_training_history(training_history)\n",
        "create_prediction_examples_table(evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oOHaZYdrtAp"
      },
      "outputs": [],
      "source": [
        "# Test prediction\n",
        "test_inchi = \"InChI=1/2C5H5.Fe/c2*1-2-4-5-3-1;/h2*1-5H;/rC10H10Fe/c1-2-4-8-6(1)11-7-3-1-5-9(7)10(11)12-8/h1-10H\"\n",
        "test_result = model.predict(test_inchi, validate=True)\n",
        "print(f\"\\n Test prediction:\")\n",
        "print(f\"   InChI: {test_result['inchi']}\")\n",
        "print(f\"   Predicted: {test_result['predicted_iupac']}\")\n",
        "if test_result['validation']:\n",
        "    print(f\"   Valid: {test_result['validation']['is_valid']}\")\n",
        "    print(f\"   Confidence: {test_result['validation']['confidence']:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "027a20b226fc4de3b12a0424ddc6a7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d7a9d8b420d4c53a76b2e9bd5c47060",
              "IPY_MODEL_95d955e30f7647f683111f5d33b3b286",
              "IPY_MODEL_52c95b1bb15c4474b0fa266da894920a"
            ],
            "layout": "IPY_MODEL_8726c8c745df424a9c2b790b27b04d5f"
          }
        },
        "04783ef6a9e54a2b9f426e83b33d657f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b6330d8188341d3a2620862f242a09a",
            "placeholder": "​",
            "style": "IPY_MODEL_131bffb067d24fe28ebf0beea4271fd1",
            "value": " 242M/242M [00:03&lt;00:00, 71.4MB/s]"
          }
        },
        "0496301f985148baacb14c7d713b3a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0884827c2e624d6c843bd3c6a578740a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "089211fa967a42b7b3e6c16bdddf674c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f4eb4558b7e4b748a10f6d15001802f",
            "placeholder": "​",
            "style": "IPY_MODEL_853a77cb5a9e4d9da75e189eb72601a2",
            "value": "generation_config.json: 100%"
          }
        },
        "0ab4246874b24ff5b5b79fa22727a7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1213615a4a654d489fe0209940289489": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "131bffb067d24fe28ebf0beea4271fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13d17dea6e7f42ef999d414c0c5ed05b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c34cae4ac6b47b4b519b5f89cbddde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0223bdee29a4adf9c97c67cc17a7cad",
              "IPY_MODEL_bd979610c163426cb3a692c29a41f011",
              "IPY_MODEL_bae2d4227e1344b083cfb26156156034"
            ],
            "layout": "IPY_MODEL_ae7943aab0a446dbb43f895cc897e3f5"
          }
        },
        "1c4fe07087e1469f8224a4f714b7af49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c75aeea824f446ba6e0e563075ad70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd223289a9846ccb7473b6c9c22c7e5",
            "placeholder": "​",
            "style": "IPY_MODEL_2101e059e88b4b9298cdfed14a910df2",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 10.3MB/s]"
          }
        },
        "1d21ebd096f14c098362e132f46b5653": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2101e059e88b4b9298cdfed14a910df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "238f929bf4084db3acfb1df7124254ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b23ce4665f2468592937664eba5d513",
            "placeholder": "​",
            "style": "IPY_MODEL_6d712f99b5b740b28005a125d5cee619",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 132kB/s]"
          }
        },
        "239ee360fe174c75992aef0c81d45342": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de70ed185ca4b0c942e0392e6a4f893": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f4eb4558b7e4b748a10f6d15001802f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "381d9c4e795a4e2088f56540a1495843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b6330d8188341d3a2620862f242a09a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f49118e83d34a598d8a09418be14654": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bf864449e644c4b9a0d54b17b98fca1",
            "placeholder": "​",
            "style": "IPY_MODEL_ce3e5c81704b41afb56e5291363a7062",
            "value": "Epoch 5/20:   5%"
          }
        },
        "3fd223289a9846ccb7473b6c9c22c7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4204953d974246048d2ec2525448ccd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4614cdd51681483bbc4ce61fe0155081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5be1a37f79c148a0943381a4a5a3c198",
              "IPY_MODEL_8451467cfee240f4bbad1b125bdc5d99",
              "IPY_MODEL_f69d6dbc5bcb4bea921655e67325ee39"
            ],
            "layout": "IPY_MODEL_6255ba44d77d4504af7dbd7d5a631a80"
          }
        },
        "4bf864449e644c4b9a0d54b17b98fca1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c95b1bb15c4474b0fa266da894920a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641998b1cd9b403e9e68e9069a22ab0b",
            "placeholder": "​",
            "style": "IPY_MODEL_70a1f93355794637a334178ae5eb9e99",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 221kB/s]"
          }
        },
        "54809ed57ec74af48b13990227683d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_089211fa967a42b7b3e6c16bdddf674c",
              "IPY_MODEL_e7f4f4cb7834484faf2534dbf15a8542",
              "IPY_MODEL_ecaacfaa711948fa8e56d3d41ac0bdfd"
            ],
            "layout": "IPY_MODEL_0496301f985148baacb14c7d713b3a1f"
          }
        },
        "5596e74309fa4107a2bcfd20085b6aee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ec0710dd0a457bb598ffd6552c1a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b23ce4665f2468592937664eba5d513": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be1a37f79c148a0943381a4a5a3c198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_834450b620a340cb93782911d62a72c1",
            "placeholder": "​",
            "style": "IPY_MODEL_381d9c4e795a4e2088f56540a1495843",
            "value": "Processing lines: 100%"
          }
        },
        "5cb28d145acd4735ac2b8158346ffc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cd13f741eac4dcf9d2b00d1b7756a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6e2ac10322497aab4178c4a6fb9346",
            "placeholder": "​",
            "style": "IPY_MODEL_e754e491b69a4ebda5014d8d21a5155b",
            "value": " 617/11861 [1:35:36&lt;28:56:53,  9.27s/it, Loss=0.0041, LR=2.66e-04]"
          }
        },
        "6255ba44d77d4504af7dbd7d5a631a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641998b1cd9b403e9e68e9069a22ab0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "678fc17633954649914c82f3ab47bd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68fde888e32d453f8c7e88a1b2709d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a9672aa70164030a4aa09d548fb2cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d712f99b5b740b28005a125d5cee619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70a1f93355794637a334178ae5eb9e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "714de1272a654f6aa87f2d8ae3a5a10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c460946728f48c9927d6748e8b900c2",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f64a35e01f124ebaa56f6a5e38604f9f",
            "value": 242043056
          }
        },
        "7307937e13b243aeb33af5e9ca27c856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e87ca35f574dc5818a519d58d3d558": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1676af438f4d0ab28a2f38c3238422": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d21ebd096f14c098362e132f46b5653",
            "placeholder": "​",
            "style": "IPY_MODEL_678fc17633954649914c82f3ab47bd8f",
            "value": "tokenizer.json: 100%"
          }
        },
        "7a6e2ac10322497aab4178c4a6fb9346": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c460946728f48c9927d6748e8b900c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd7724eae094afa921fb30805e6333c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b81f4f82464e909c8c8d733c1d9fde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834450b620a340cb93782911d62a72c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8451467cfee240f4bbad1b125bdc5d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2da89609ace447bbaf6f0a63a113e20",
            "max": 67781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1fa8b2a2bec400ea8505b12ced9b783",
            "value": 67781
          }
        },
        "853a77cb5a9e4d9da75e189eb72601a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8726c8c745df424a9c2b790b27b04d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874d4c49068d4bf8a1946261f605cc27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7a9d8b420d4c53a76b2e9bd5c47060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e88f21c88624dffaca64e22e76b9a50",
            "placeholder": "​",
            "style": "IPY_MODEL_d44fc5671aa8452a854b11afc46fc180",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8e69a06be0da49678a546a2242856ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_874d4c49068d4bf8a1946261f605cc27",
            "max": 11861,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d99cb88ce1624eb18176b64a41db9dfa",
            "value": 617
          }
        },
        "8e88f21c88624dffaca64e22e76b9a50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d955e30f7647f683111f5d33b3b286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5596e74309fa4107a2bcfd20085b6aee",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3946d463a7a4dc5a75e046b894e9225",
            "value": 2324
          }
        },
        "9add9c82ae554e61a6f44b79e2a422be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a048d60c17574124af16db8b0dca9894": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1fa8b2a2bec400ea8505b12ced9b783": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae7943aab0a446dbb43f895cc897e3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0223bdee29a4adf9c97c67cc17a7cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bdb55ef08c4f3fa2c599843150ecb5",
            "placeholder": "​",
            "style": "IPY_MODEL_e195ad1e287d4eac9eb289d4a0d96bf3",
            "value": "spiece.model: 100%"
          }
        },
        "b15c2f4b737449f49a270a5548f95c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c66e77dc32d14070a0987e41e6ae79d0",
              "IPY_MODEL_714de1272a654f6aa87f2d8ae3a5a10f",
              "IPY_MODEL_04783ef6a9e54a2b9f426e83b33d657f"
            ],
            "layout": "IPY_MODEL_0884827c2e624d6c843bd3c6a578740a"
          }
        },
        "b276a6c1378648098bce3ab305a28974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f49118e83d34a598d8a09418be14654",
              "IPY_MODEL_8e69a06be0da49678a546a2242856ea9",
              "IPY_MODEL_5cd13f741eac4dcf9d2b00d1b7756a30"
            ],
            "layout": "IPY_MODEL_e224e162e47f48dea60739b8d5378d9b"
          }
        },
        "bae2d4227e1344b083cfb26156156034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1213615a4a654d489fe0209940289489",
            "placeholder": "​",
            "style": "IPY_MODEL_6a9672aa70164030a4aa09d548fb2cfd",
            "value": " 792k/792k [00:00&lt;00:00, 13.5MB/s]"
          }
        },
        "bd979610c163426cb3a692c29a41f011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2de70ed185ca4b0c942e0392e6a4f893",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cb28d145acd4735ac2b8158346ffc87",
            "value": 791656
          }
        },
        "be8dc65fb5cb4694b31c9e14dd94701f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1bdb55ef08c4f3fa2c599843150ecb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3946d463a7a4dc5a75e046b894e9225": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c66e77dc32d14070a0987e41e6ae79d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13d17dea6e7f42ef999d414c0c5ed05b",
            "placeholder": "​",
            "style": "IPY_MODEL_9add9c82ae554e61a6f44b79e2a422be",
            "value": "model.safetensors: 100%"
          }
        },
        "ce3e5c81704b41afb56e5291363a7062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d44fc5671aa8452a854b11afc46fc180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d99cb88ce1624eb18176b64a41db9dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da3c022c494b42788d8cc99ceefc2d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2564281e6244b5180bd2b8629470678",
              "IPY_MODEL_f437496339284ebd92d2b717679abd6a",
              "IPY_MODEL_238f929bf4084db3acfb1df7124254ec"
            ],
            "layout": "IPY_MODEL_73e87ca35f574dc5818a519d58d3d558"
          }
        },
        "de1e0063323a49b8bbc91b6069183827": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7307937e13b243aeb33af5e9ca27c856",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ab4246874b24ff5b5b79fa22727a7c3",
            "value": 1389353
          }
        },
        "e195ad1e287d4eac9eb289d4a0d96bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e224e162e47f48dea60739b8d5378d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2564281e6244b5180bd2b8629470678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239ee360fe174c75992aef0c81d45342",
            "placeholder": "​",
            "style": "IPY_MODEL_58ec0710dd0a457bb598ffd6552c1a30",
            "value": "config.json: 100%"
          }
        },
        "e2da89609ace447bbaf6f0a63a113e20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e754e491b69a4ebda5014d8d21a5155b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7f4f4cb7834484faf2534dbf15a8542": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a048d60c17574124af16db8b0dca9894",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4dd0782cc9c46a1bb41b01dd580a5f4",
            "value": 147
          }
        },
        "e9d6d9b0556d4a47a8d45840d41dade0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecaacfaa711948fa8e56d3d41ac0bdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4fe07087e1469f8224a4f714b7af49",
            "placeholder": "​",
            "style": "IPY_MODEL_4204953d974246048d2ec2525448ccd9",
            "value": " 147/147 [00:00&lt;00:00, 3.51kB/s]"
          }
        },
        "f437496339284ebd92d2b717679abd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9d6d9b0556d4a47a8d45840d41dade0",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be8dc65fb5cb4694b31c9e14dd94701f",
            "value": 1206
          }
        },
        "f4dd0782cc9c46a1bb41b01dd580a5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f64a35e01f124ebaa56f6a5e38604f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f69d6dbc5bcb4bea921655e67325ee39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b81f4f82464e909c8c8d733c1d9fde",
            "placeholder": "​",
            "style": "IPY_MODEL_68fde888e32d453f8c7e88a1b2709d8a",
            "value": " 67781/67781 [00:00&lt;00:00, 288635.46it/s]"
          }
        },
        "f6a8f19803424a378b2865736f4db54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a1676af438f4d0ab28a2f38c3238422",
              "IPY_MODEL_de1e0063323a49b8bbc91b6069183827",
              "IPY_MODEL_1c75aeea824f446ba6e0e563075ad70c"
            ],
            "layout": "IPY_MODEL_7dd7724eae094afa921fb30805e6333c"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}